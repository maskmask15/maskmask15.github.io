
<!DOCTYPE html><html lang="zh-CN">

<head>
  <meta charset="utf-8">
  <meta name="hexo-theme" content="https://github.com/xaoxuu/hexo-theme-stellar/tree/1.32.4" theme-name="Stellar" theme-version="1.32.4">
  
  
  <meta name="generator" content="Hexo 7.3.0">
  <meta http-equiv='x-dns-prefetch-control' content='on' />
  <link rel="preconnect" href="https://gcore.jsdelivr.net" crossorigin><link rel="preconnect" href="https://unpkg.com" crossorigin><link rel="preconnect" href="https://cdn.bootcdn.net" crossorigin>
  <meta name="renderer" content="webkit">
  <meta name="force-rendering" content="webkit">
  <meta http-equiv="X-UA-Compatible" content="IE=Edge,chrome=1">
  <meta name="HandheldFriendly" content="True" >
  <meta name="mobile-web-app-capable" content="yes">
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="theme-color" media="(prefers-color-scheme: dark)" content="#000">
  <meta name="theme-color" content="#f9fafb">
  <title>AI编译器学习记录 01 - LuYh</title>

  
    <meta name="description" content="AI编译器学习记录 01">
<meta property="og:type" content="article">
<meta property="og:title" content="AI编译器学习记录 01">
<meta property="og:url" content="https://maskmask15.github.io/2025/09/25/AI%E7%BC%96%E8%AF%91%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%9501/">
<meta property="og:site_name" content="LuYh">
<meta property="og:description" content="AI编译器学习记录 01">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://maskmask15.github.io/assets/LuYh/avatar/LYuh_icon.jpg">
<meta property="article:published_time" content="2025-09-25T07:27:16.000Z">
<meta property="article:modified_time" content="2025-09-28T11:32:39.667Z">
<meta property="article:author" content="LuYhhhhh">
<meta property="article:tag" content="AI Sys">
<meta property="article:tag" content="编译器">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://maskmask15.github.io/assets/LuYh/avatar/LYuh_icon.jpg">
  
  
  
  <meta name="keywords" content="AI Sys,编译器">

  <!-- feed -->
  

  <link rel="stylesheet" href="/css/main.css?v=1.32.4">


  

  

  <script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"LuYhhhhh","sameAs":[],"image":"/assets/LuYh/avatar/LYuh_icon.jpg"},"dateCreated":"2025-09-25T15:27:16+08:00","dateModified":"2025-09-28T19:32:39+08:00","datePublished":"2025-09-25T15:27:16+08:00","description":"","headline":"AI编译器学习记录 01","mainEntityOfPage":{"@type":"WebPage","@id":"https://maskmask15.github.io/2025/09/25/AI%E7%BC%96%E8%AF%91%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%9501/"},"publisher":{"@type":"Organization","name":"LuYhhhhh","sameAs":[],"image":"/assets/LuYh/avatar/LYuh_icon.jpg","logo":{"@type":"ImageObject","url":"/assets/LuYh/avatar/LYuh_icon.jpg"}},"url":"https://maskmask15.github.io/2025/09/25/AI%E7%BC%96%E8%AF%91%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%9501/","keywords":"AI Sys, 编译器","image":[]}</script>
  <link rel="apple-touch-icon" sizes="180x180" href="/assets/xaoxuu/favicon/apple-touch-icon.png"><link rel="icon" type="image/png" sizes="32x32" href="/assets/xaoxuu/favicon/favicon-32x32.png"><link rel="icon" type="image/png" sizes="16x16" href="/assets/xaoxuu/favicon/favicon-16x16.png"><link rel="manifest" href="/assets/xaoxuu/favicon/site.webmanifest"><link rel="shortcut icon" href="/assets/xaoxuu/favicon/favicon.ico"><meta name="theme-color" content="#f8f8f8"><link rel="stylesheet" href="https://cdn.bootcdn.net/ajax/libs/lxgw-wenkai-screen-webfont/1.7.0/style.min.css" media="all" />

  <script>
    window.MathJax = {
      tex: {
        inlineMath: [['\\(','\\)']],
        displayMath: [['$$','$$']],
        macros: {},
        // 调整公式上下间距
        displayAlign: 'center',
        displayIndent: '0pt'
      },
      chtml: {
        scale: 1.8,
        // mtextInheritFont: true,
        displayIndent: '0pt',
        displayAlign: 'center',
      }
    };
    </script>
    
    
    <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js" id="MathJax-script" async></script>
    
    <style>
    /* 调整所有 display 公式上下间距 */
    .MathJax_Display .mjx-chtml {
        font-size: 0.7em !important;
        margin-top: 0pt !important;
        margin-bottom: 0pt !important;
        line-height: 1em;       /* 行高压紧公式 */
    }

    /* 可选：调整下标字体大小 */
    .MathJax .mjx-sub {
        font-size: 0.7em !important;
    }

    </style>
    
</head>
<body>

<div class="l_body content" id="start" layout="post" type="tech" ><aside class="l_left"><div class="sidebg"></div><div class="leftbar-container">


<header class="header"><div class="logo-wrap"><div class="icon"><img no-lazy class="icon" src="/assets/LYuh_icon.jpg" onerror="javascript:this.classList.add('error');this.src='https://gcore.jsdelivr.net/gh/cdn-x/placeholder@1.0.12/image/2659360.svg';"></div><a class="title" href="/"><div class="main">LuYh</div><div class="sub normal cap">顶峰相见</div><div class="sub hover cap" style="opacity:0"> Designed by LuYhhhhh</div></a></div></header>

<div class="nav-area">

<nav class="menu dis-select"><a class="nav-item active" title="博客" href="/" style="color:#1BCDFC"><svg xmlns="http://www.w3.org/2000/svg" width="32" height="32" viewBox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M5.879 2.879C5 3.757 5 5.172 5 8v8c0 2.828 0 4.243.879 5.121C6.757 22 8.172 22 11 22h2c2.828 0 4.243 0 5.121-.879C19 20.243 19 18.828 19 16V8c0-2.828 0-4.243-.879-5.121C17.243 2 15.828 2 13 2h-2c-2.828 0-4.243 0-5.121.879M8.25 17a.75.75 0 0 1 .75-.75h3a.75.75 0 0 1 0 1.5H9a.75.75 0 0 1-.75-.75M9 12.25a.75.75 0 0 0 0 1.5h6a.75.75 0 0 0 0-1.5zM8.25 9A.75.75 0 0 1 9 8.25h6a.75.75 0 0 1 0 1.5H9A.75.75 0 0 1 8.25 9" clip-rule="evenodd"/><path fill="currentColor" d="M5.235 4.058C5 4.941 5 6.177 5 8v8c0 1.823 0 3.058.235 3.942L5 19.924c-.975-.096-1.631-.313-2.121-.803C2 18.243 2 16.828 2 14v-4c0-2.829 0-4.243.879-5.121c.49-.49 1.146-.707 2.121-.803zm13.53 15.884C19 19.058 19 17.822 19 16V8c0-1.823 0-3.059-.235-3.942l.235.018c.975.096 1.631.313 2.121.803C22 5.757 22 7.17 22 9.999v4c0 2.83 0 4.243-.879 5.122c-.49.49-1.146.707-2.121.803z" opacity=".5"/></svg></a><a class="nav-item" title="专栏" href="/topic/" style="color:#3DC550"><svg xmlns="http://www.w3.org/2000/svg" width="32" height="32" viewBox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M14.25 4.48v3.057c0 .111 0 .27.02.406a.936.936 0 0 0 .445.683a.96.96 0 0 0 .783.072c.13-.04.272-.108.378-.159L17 8.005l1.124.534c.106.05.248.119.378.16a.958.958 0 0 0 .783-.073a.936.936 0 0 0 .444-.683c.021-.136.021-.295.021-.406V3.031c.113-.005.224-.01.332-.013C21.154 2.98 22 3.86 22 4.933v11.21c0 1.112-.906 2.01-2.015 2.08c-.97.06-2.108.179-2.985.41c-1.082.286-1.99 1.068-3.373 1.436c-.626.167-1.324.257-1.627.323V5.174c.32-.079 1.382-.203 1.674-.371c.184-.107.377-.216.576-.323m5.478 8.338a.75.75 0 0 1-.546.91l-4 1a.75.75 0 0 1-.364-1.456l4-1a.75.75 0 0 1 .91.546" clip-rule="evenodd"/><path fill="currentColor" d="M18.25 3.151c-.62.073-1.23.18-1.75.336a8.2 8.2 0 0 0-.75.27v3.182l.75-.356l.008-.005a1.13 1.13 0 0 1 .492-.13c.047 0 .094.004.138.01c.175.029.315.1.354.12l.009.005l.749.356V3.647z"/><path fill="currentColor" d="M12 5.214c-.334-.064-1.057-.161-1.718-.339C8.938 4.515 8.05 3.765 7 3.487c-.887-.234-2.041-.352-3.018-.412C2.886 3.007 2 3.9 2 4.998v11.146c0 1.11.906 2.01 2.015 2.079c.97.06 2.108.179 2.985.41c.486.129 1.216.431 1.873.726c1.005.451 2.052.797 3.127 1.034z" opacity=".5"/><path fill="currentColor" d="M4.273 12.818a.75.75 0 0 1 .91-.545l4 1a.75.75 0 1 1-.365 1.455l-4-1a.75.75 0 0 1-.545-.91m.909-4.545a.75.75 0 1 0-.364 1.455l4 1a.75.75 0 0 0 .364-1.455z"/></svg></a><a class="nav-item" title="探索" href="/explore/" style="color:#FA6400"><svg xmlns="http://www.w3.org/2000/svg" width="32" height="32" viewBox="0 0 24 24"><path fill="currentColor" d="M20 12a8 8 0 1 1-16 0a8 8 0 0 1 16 0" opacity=".5"/><path fill="currentColor" d="M17.712 5.453c1.047-.193 2.006-.259 2.797-.152c.77.103 1.536.393 1.956 1.064c.446.714.312 1.542-.012 2.258c-.33.728-.918 1.499-1.672 2.268c-1.516 1.547-3.836 3.226-6.597 4.697c-2.763 1.472-5.495 2.484-7.694 2.92c-1.095.217-2.098.299-2.923.201c-.8-.095-1.6-.383-2.032-1.075c-.47-.752-.296-1.63.07-2.379c.375-.768 1.032-1.586 1.872-2.403L4 12.416c0 .219.083.71.168 1.146c.045.23.09.444.123.596c-.652.666-1.098 1.263-1.339 1.756c-.277.567-.208.825-.145.925c.072.116.305.305.937.38c.609.073 1.44.018 2.455-.183c2.02-.4 4.613-1.351 7.28-2.772c2.667-1.42 4.85-3.015 6.23-4.423c.694-.707 1.15-1.334 1.377-1.836c.233-.515.167-.75.107-.844c-.07-.112-.289-.294-.883-.374c-.542-.072-1.272-.041-2.163.112L16.87 5.656c.338-.101.658-.17.842-.203"/></svg></a><a class="nav-item" title="社交" href="/friends/" style="color:#F44336"><svg xmlns="http://www.w3.org/2000/svg" width="32" height="32" viewBox="0 0 24 24"><path fill="currentColor" d="m13.629 20.472l-.542.916c-.483.816-1.69.816-2.174 0l-.542-.916c-.42-.71-.63-1.066-.968-1.262c-.338-.197-.763-.204-1.613-.219c-1.256-.021-2.043-.098-2.703-.372a5 5 0 0 1-2.706-2.706C2 14.995 2 13.83 2 11.5v-1c0-3.273 0-4.91.737-6.112a5 5 0 0 1 1.65-1.651C5.59 2 7.228 2 10.5 2h3c3.273 0 4.91 0 6.113.737a5 5 0 0 1 1.65 1.65C22 5.59 22 7.228 22 10.5v1c0 2.33 0 3.495-.38 4.413a5 5 0 0 1-2.707 2.706c-.66.274-1.447.35-2.703.372c-.85.015-1.275.022-1.613.219c-.338.196-.548.551-.968 1.262" opacity=".5"/><path fill="currentColor" d="M10.99 14.308c-1.327-.978-3.49-2.84-3.49-4.593c0-2.677 2.475-3.677 4.5-1.609c2.025-2.068 4.5-1.068 4.5 1.609c0 1.752-2.163 3.615-3.49 4.593c-.454.335-.681.502-1.01.502c-.329 0-.556-.167-1.01-.502"/></svg></a></nav>
</div>
<div class="widgets">
<div class="search-wrapper" id="search-wrapper"><form class="search-form"><a class="search-button" onclick="document.getElementById(&quot;search-input&quot;).focus();"><svg t="1705074644177" viewBox="0 0 1025 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="1560" width="200" height="200"><path d="M1008.839137 935.96571L792.364903 719.491476a56.783488 56.783488 0 0 0-80.152866 0 358.53545 358.53545 0 1 1 100.857314-335.166073 362.840335 362.840335 0 0 1-3.689902 170.145468 51.248635 51.248635 0 1 0 99.217358 26.444296 462.057693 462.057693 0 1 0-158.255785 242.303546l185.930047 185.725053a51.248635 51.248635 0 0 0 72.568068 0 51.248635 51.248635 0 0 0 0-72.978056z" p-id="1561"></path><path d="M616.479587 615.969233a50.428657 50.428657 0 0 0-61.498362-5.534852 174.655348 174.655348 0 0 1-177.525271 3.484907 49.403684 49.403684 0 0 0-58.833433 6.76482l-3.074918 2.869923a49.403684 49.403684 0 0 0 8.609771 78.10292 277.767601 277.767601 0 0 0 286.992355-5.739847 49.403684 49.403684 0 0 0 8.404776-76.667958z" p-id="1562"></path></svg></a><input type="text" class="search-input" id="search-input" placeholder="站内搜索"></form><div id="search-result"></div><div class="search-no-result">没有找到内容！</div></div>



<widget class="widget-wrapper recent post-list"><div class="widget-header dis-select"><span class="name">最近更新</span></div><div class="widget-body fs14"><a class="item title" href="/2025/09/25/AI%E7%BC%96%E8%AF%91%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%9501/"><span class="title">AI编译器学习记录 01</span></a><a class="item title" href="/2025/09/24/LLVM%E5%AD%A6%E4%B9%A002/"><span class="title">LLVM 学习记录 0x</span></a><a class="item title" href="/2025/09/24/LLVM%E5%AD%A6%E4%B9%A001/"><span class="title">LLVM 学习记录 0x</span></a><a class="item title" href="/2025/08/21/RK3588-%E5%B9%B3%E5%8F%B0-YOLO11-Seg-%E9%83%A8%E7%BD%B2%E4%B8%8E%E4%BC%98%E5%8C%96/"><span class="title">RK3588 平台部署 YOLO11-Seg</span></a><a class="item title" href="/2025/08/22/AI%20Sys%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%9501/"><span class="title">AI Sys学习记录 --- AI 计算体系概述</span></a><a class="item title" href="/2025/08/26/leetcode%E5%88%B7%E9%A2%98%E8%AE%B0%E5%BD%95-20250811%EF%BC%8Cday20%EF%BC%8C%E4%BA%8C%E5%8F%89%E6%A0%91/"><span class="title">leetcode刷题记录-20250811，day20，二叉树</span></a><a class="item title" href="/2025/08/21/leetcode%E5%88%B7%E9%A2%98%E8%AE%B0%E5%BD%95-20250808%EF%BC%8Cday17%EF%BC%8C%E4%BA%8C%E5%8F%89%E6%A0%91/"><span class="title">leetcode刷题记录-20250808，day17，二叉树</span></a><a class="item title" href="/2025/08/22/leetcode%E5%88%B7%E9%A2%98%E8%AE%B0%E5%BD%95-20250809%EF%BC%8Cday18%EF%BC%8C%E4%BA%8C%E5%8F%89%E6%A0%91/"><span class="title">leetcode刷题记录-20250809，day18，二叉树</span></a><a class="item title" href="/2025/08/25/Versal-ACAP%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/"><span class="title">Versal ACAP学习记录</span></a></div></widget>
</div>

</div></aside><div class="l_main" id="main">





<div class="article banner top">
  <div class="content">
    <div class="top bread-nav footnote"><div class="left"><div class="flex-row" id="breadcrumb"><a class="cap breadcrumb" href="/">主页</a>
<span class="sep"></span><a class="cap breadcrumb" href="/">文章</a><span class="sep"></span><a class="cap breadcrumb-link" href="/categories/AI-Sys/">AI Sys</a></div>
<div class="flex-row" id="post-meta"><span class="text created">发布于：<time datetime="2025-09-25T07:27:16.000Z">2025-09-25</time></span><span class="sep updated"></span><span class="text updated">更新于：<time datetime="2025-09-28T11:32:39.667Z">2025-09-28</time></span></div></div></div>
    
    <div class="bottom only-title">
      
      <div class="text-area">
        <h1 class="text title"><span>AI编译器学习记录 01</span></h1>
        
      </div>
    </div>
    
  </div>
  </div><article class="md-text content"><p>AI编译器学习记录 01, <a target="_blank" rel="noopener" href="https://infrasys-ai.github.io/aisystem-docs/03Compiler02AICompiler/README.html">跟随大佬的脚步</a></p>
<h1 id="AI编译器发展过程"><a href="#AI编译器发展过程" class="headerlink" title="AI编译器发展过程"></a>AI编译器发展过程</h1><ul>
<li><p>第一阶段朴素的AI编译器，tensorflow的早期模式。</p>
</li>
<li><p>第二阶段专用的AI编译器，pytorch以及类pytorch。将类pytorch的表达转换成图层的IR进行优化。希望能够打开计算图图和算子的边界进行重新组合优化。关键是大算子怎么打开，小算子怎么融合。<br>  <strong>ZOMI大佬提出的一个问题很好，AI框架和AI编译器的界限在哪里？一个AI框架就是一个AI编译器么？还是AI编译器只是AI框架的一部分呢？</strong><br>  在我的理解上，因为要提升所谓的推理性能，AI框架要内置AI编译器。但是AI框架不等于AI编译器，框架可调用编译器，编译器属于框架的后端。编译器可以独立与框架运行，比如TVM，TensorRT等。AI框架的硬件感知力较弱，需要编译器来针对特定目标平台做部署。</p>
</li>
<li><p>第三阶段通用的AI编译器<br><a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1qD4y1Y73e?t=488.9">图片取自ZOMI大佬</a></p>
<img src="/assets/AIcompiler_stage.png" alt="AIcompiler_stage" width="700"></li>
</ul>
<h1 id="AI编译器的通用架构"><a href="#AI编译器的通用架构" class="headerlink" title="AI编译器的通用架构"></a>AI编译器的通用架构</h1><p><a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1qD4y1Y73e?t=149.2">图片取自ZOMI大佬</a>，AI编译器分为前端和后端，分别做硬件无关和硬件相关的处理。前端包括计算图的编译器以及算子的编译器。有不同的IR和不同的pass，和LLVM挺像的。</p>
<figure style="text-align: center;">
  <img src="/assets/AIcompiler.png" alt="AIcompiler" width="700">
  <figcaption>图 1：AI 编译器的整体架构示意图</figcaption>
</figure>


<h1 id="IR"><a href="#IR" class="headerlink" title="IR"></a>IR</h1><ul>
<li>High-level IR：用于表示计算图，表示神经网络。主要是为了解决传统编译器中难以表达深度学习模型中复杂运算这一问题，为了实现更高效的优化所以新设计了一套IR。比如TVM中的Relay IR。</li>
<li>Low-level IR：类似于传统编译器，能够在更细粒度的层面（比如代码、指令集层面）上表示模型，从而能够针对与硬件进行优化。比如TVM中的TIR。</li>
</ul>
<h1 id="前后端优化区别"><a href="#前后端优化区别" class="headerlink" title="前后端优化区别"></a>前后端优化区别</h1><ul>
<li>前端优化：输入计算图，更关注计算图整体拓扑结构，而不关心算子的具体实现。在AI编译器的前端优化中，对算子节点进行融合、消除、化简等操作，使得计算图计算和存储开销最小。</li>
<li>后端优化：输入是低级IR，关注算子节点的内部具体实现，针对具体实现使性能达最优。重点关注节点的输入、输出、内存循环方式和计算逻辑。</li>
</ul>
<h1 id="前端优化"><a href="#前端优化" class="headerlink" title="前端优化"></a>前端优化</h1><p>构造计算图，前端进行图级的优化。图提供了计算全局概述，所以容易在图级发现和执行许多优化，且与硬件无关，这意味着任何后端目标都可应用计算图优化。ZOMI大佬将前端优化分成了<strong>真正面向图层的优化</strong>和<strong>传统的面向DAG图的优化</strong>，目前来说个人感觉其实界限没有那么明确。不确定大佬是不是想表达面向单个算子&#x2F;层的优化以及面向整个DAG图的优化，一个是<strong>局部视角</strong>，一个是<strong>全局视角</strong>。学习完前端优化之后，大佬解释了为什么这么划分呢，其实是分成了<strong>神经网络相关的优化以及代码&#x2F;计算层面的优化</strong>。</p>
<ul>
<li>节点级优化，比如 Zero-dim-tensor dlimination（零维度张量消除）、 Nop Elimination。</li>
<li>块级优化，比如代数简化、常量折叠、算子融合。将多个算子变成一个块，变成一个子图的优化。</li>
<li>数据流级优化，比如Common sub-exoression elimination、DEC。更像是 Low-level IR上的优化。<br><a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1ne411w7n2?t=102.0">图片取自ZOMI大佬</a><img src="/assets/AIcompiler_frontend.png" alt="AIcompiler_frontend" width="700"></li>
</ul>
<h2 id="真正的面向图层的优化，神经网络相关的优化"><a href="#真正的面向图层的优化，神经网络相关的优化" class="headerlink" title="真正的面向图层的优化，神经网络相关的优化"></a>真正的面向图层的优化，神经网络相关的优化</h2><h3 id="算子融合-OPFusion"><a href="#算子融合-OPFusion" class="headerlink" title="算子融合 OPFusion"></a>算子融合 OPFusion</h3><p><strong>算子融合的本质就是要”减少访存 + 减少调度 + 提高并行”。融合的深度和粒度往往直接决定了最终的推理性能。</strong></p>
<ol>
<li>算子融合方式<ul>
<li>水平融合，将输入相同，计算类型相同的算子融合为一个算子，在同一个kernel中执行。可减少访问输入数据的次数，提高并行度。</li>
<li>垂直融合，将前后相邻的算子链融合成一个算子，减少中间张量的存取。</li>
<li>算子内融合，将一系列小的逐元素的操作融合成一个大的复合算子。减少kernel的启动次数，存取次数。</li>
<li>图级融合，识别特定的计算子图模式，将其视为单一算子。可大幅度减少调度和存取，</li>
</ul>
</li>
<li>算子融合示例，以经典的Conv+BN+Relu融合为例（<strong>后续会更新这部分的详细解释以及数学公式推理。</strong>）<ul>
<li>第一种是我之前学算子融合时了解到的方式。就是将Conv+BN合成一个等价的带bias的卷积，再将ReLU合并进去。灵活性较低，对于普通的CPU&#x2F;GPU推理较为友好。</li>
<li>第二种是ZOMI大佬说的这种，将BN层拆封成BN_A和BN_B，BN_A计算均值和方差，BN_B完成归一化和缩放。BN_B与激活函数融合，BN_A与卷积层融合。这种方式更适合流水线硬件优化，更灵活。</li>
</ul>
</li>
<li>融合的规则和策略，ZOMI大佬这里是讲了TVM所定义的方法，是基于支配树来实现的。 <ul>
<li>TVM 支配树，就是由各个点的支配点所构成的树。<ul>
<li>支配点，所有能够到达当前节点的路径的公共祖先点（LCA）</li>
<li>作用：检查每个节点到其支配点的节点是否符合融合条件。</li>
<li>融合的基本规则是融合掉的节点不会对剩下的节点产生影响。</li>
<li>生成：根据DAG生成DFS（深度优先搜索）树，根据DFS树及对应的边生成DOM树，加入一个Group数据结构来描述多个节点能否被融合。</li>
</ul>
</li>
<li>TVM 算子融合流程<ol>
<li>通过 AST 转换为 Relay IR（High-level IR），遍历 Relay IR。</li>
<li>建立DAG用于生成支配树以及分析。</li>
<li>应用算子融合算法。</li>
</ol>
</li>
<li>TVM 融合规则<ol>
<li>Injective映射，one2one map</li>
<li>Reduction，简约函数，从输入到输出具有降维性质，比如相加之后求和&#x2F;求最值。</li>
<li>Complex-out-fusable，人工设定一些融合规则，比如conv+bn+relu</li>
<li>Opaque，无法被融合的算子，比如sort</li>
</ol>
</li>
</ul>
</li>
</ol>
<h3 id="布局转换-Layout-Transform"><a href="#布局转换-Layout-Transform" class="headerlink" title="布局转换 Layout Transform"></a>布局转换 Layout Transform</h3><h4 id="张量数据布局"><a href="#张量数据布局" class="headerlink" title="张量数据布局"></a>张量数据布局</h4><p><strong>内存对齐</strong><br>内存对齐和数据在内存中的位置有关，内存对齐以字节为单位进行，若一个变量的内存地址正好等于它的长度(sizeof(变量类型))的整数倍，则称为自然对齐。<br>因为硬件是按照字节块的方式读取内存，所以尽管内存以字节为单位，也需要内存对齐来充分的利用硬件性能。以字节快进行内存访问的好处：</p>
<ol>
<li>简单来说就是可以提升其访问速度</li>
<li>原子性：在一个对齐的内存字上操作时，意味着没有指令可以中断其操作，对于无锁数据结构（是指在多线程的环境下，不加所仍然能安全操作的数据结构）和其他并发范式的正确性至关重要。</li>
</ol>
<h4 id="NCHW与NHWC"><a href="#NCHW与NHWC" class="headerlink" title="NCHW与NHWC"></a>NCHW与NHWC</h4><p>存储的数据一样，但是存放顺序不一样就是导致性能的差异。</p>
<ul>
<li>NCHW，假设有一个(1,3,640,640)的图片，就是相当于按行优先访问每个通道上的数据。这种我可以依次取到每个通道上的所有数据。可以很高效的将多个通道维度的数据转换为一个大矩阵，适合使用img2col+GEMM将卷积等算子转换为矩阵乘的硬件设备。</li>
<li>NHWC，这个就是相当于先访问每个元素的所有通道的数据，然后再按行优先访问。这种数据排布方式使每个像素的所有通道的内存都是连续的，很方便硬件拿到完整的通道数据。对于conv1*1这种算子或者不将算子展开为矩阵乘的硬件来说很友好。</li>
<li>但是对于实际使用来说，单纯的NCHW和NHWC并不能满足高性能计算的要求。比如有的硬件厂商会把Channel分成多个tile，使其与硬件的向量寄存器或者矩阵计算单元一类的东西对齐，可以提高硬件资源的利用率。或者针对不同算子使用的数据布局也不相同。<br><strong>连续张量与非连续张量</strong></li>
<li>连续张量：最简单的就是创建或clone一个张量，内存的存储顺序和逻辑上的访问顺序是一致的。</li>
<li>非连续张量：这种就是说内存上的存储顺序没变，但是访问方式改变了，比如将新创建的张量进行转置或者切片。</li>
</ul>
<h4 id="AI编译布局转换优化"><a href="#AI编译布局转换优化" class="headerlink" title="AI编译布局转换优化"></a>AI编译布局转换优化</h4><ul>
<li>目的：将数据布局转换为后端设备友好的形式。因为边缘设备通常都是异构计算平台，所以AI编译器需要提供一种跨硬件执行布局转化的方法。</li>
<li>方式：在计算图（DAG）中为张量寻找最优的数据布局，并在必要时自动插入布局转换节点（比如一个cast算子，去转换前后布局），以确保算子间的格式匹配和性能最优。<br><strong>训练场景：</strong>在不改变原计算图的情况下，前后两个算子数据排布不同，就需要插入转换算子（推理场景下不也一样么。。）<br><strong>推理场景：</strong>ZOMI大佬主要提到了一个权重布局转换，比如在训练框架下卷积权重以[Cout, Cin, Kw, Kh]这个格式存储，在硬件上推理时不太友好，编译器就需要对齐进行重新排布，一般来说是对输入输出通道进行重新排布，适配硬件格式。</li>
</ul>
<h3 id="内存分配-优化"><a href="#内存分配-优化" class="headerlink" title="内存分配&#x2F;优化"></a>内存分配&#x2F;优化</h3><h4 id="内存划分"><a href="#内存划分" class="headerlink" title="内存划分"></a>内存划分</h4><ul>
<li>静态内存，（这种比如就是在硬件上部署神经网络，初始化时需要一次性申请完的内存。）<ol>
<li>权重参数（Parameters）</li>
<li>网络常量（Value Node），不能够被折叠的常量，在训练或者推理时需要被频繁使用的。</li>
<li>网络输出（Output）</li>
</ol>
</li>
<li>动态内存，（这个应该就是模型推理过程中产生的中间结果）<ol>
<li>算子的输出tensor</li>
<li>workspace tensor，部分算子在计算过程中的临时buf</li>
</ol>
</li>
</ul>
<h4 id="内存优化方法。（没有提到权重复用，输入复用，输出复用，可能这种更准确地说属于数据复用，数据流或者存取方式上的优化）"><a href="#内存优化方法。（没有提到权重复用，输入复用，输出复用，可能这种更准确地说属于数据复用，数据流或者存取方式上的优化）" class="headerlink" title="内存优化方法。（没有提到权重复用，输入复用，输出复用，可能这种更准确地说属于数据复用，数据流或者存取方式上的优化）"></a>内存优化方法。（没有提到权重复用，输入复用，输出复用，可能这种更准确地说属于数据复用，数据流或者存取方式上的优化）</h4><ul>
<li>以空间换内存，将临时用不到的模块，卸载至CPU（CPU Offload）</li>
<li>以计算换内存，重计算（Gradient Checkpointing），对于模型的中间计算结果来说，在存取速度慢于重新计算一遍的时候，就不去存取了，直接重新计算，在大模型中这个用的比较多。对于某些AI芯片来说，内存带宽比较低，就可以不去存中间结果了。</li>
<li>模型压缩，在推理时，量化肯定会要做的。以低比特的数据来表示，换取模型更小的内存占用，同时精度掉点可以接受的情况下。</li>
</ul>
<h4 id="内存复用（重点）"><a href="#内存复用（重点）" class="headerlink" title="内存复用（重点）"></a><strong>内存复用（重点）</strong></h4><ol>
<li>替代操作（inplace operation）：如果一块内存不再需要使用了，且下一次操作时element-wise，可以原地覆盖内存。</li>
<li>内存共享（Memory sharing）：两个数据使用内存大小相同，且由一个数据参与计算后不再需要，后一个数据可以覆盖前一个数据。</li>
</ol>
<p><strong>question</strong></p>
<ul>
<li>怎样正确的分配内存？（ZOMI大佬提到和传统编译器内存优化方法比较像）<br>  <a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1nM411879s?t=830.5">一个传统的优化方法，找Inplace operation和memory sharing。图片取自ZOMI大佬</a>  <img src="/assets/memory_allocate.png" alt="memory_allocate" width="700">
  在这个例子中，首先初始化每个节点的状态；1：为B算子分配tag；2：为C算子分配tag，检查之前的算子B是否能做inplace operation，发现不能，因为B算子还需要去做一个操作；3：分配tag给F，检查之前的B和C是否可以inplace，发现B后续阶段用不到了，那就可以inplace；4：那就把B算子申请的内存给E去用，假设存在操作相同的算子，那就也可以使用memory sharing。后续就一直重复类似的操作，直到计算图结束。最后得到一个内存优化计划。</li>
<li>上述举得例子分配逻辑主要是串行的，那并行时应该怎么做呢？（第一感觉应该是和串行类似吧，只不过要尽可能的保留并行操作）<br>  <a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1nM411879s?t=845.1">ZOMI大佬举了两个例子。图片取自ZOMI大佬</a>  <img src="/assets/memory_allocate_q2.png" alt="memory_allocate_q2" width="700">
  两种分配方案都有效的，但是左侧这个由很多的并行依赖。并不能真正意义上做到并行。右侧这个两条并线分别取做内存优化，可以更好的做并行操作。同时大佬还提到了左侧这个不能在两个NPU核上做。</li>
</ul>
<p><strong>在做内存分配时要尽量允许更多的并行，在DAG中去尝试找到一个最长的路径，根据这个最长路径去做inplace和co-share操作</strong></p>
<h2 id="传统的面向DAG图的优化，代码-计算层面的优化"><a href="#传统的面向DAG图的优化，代码-计算层面的优化" class="headerlink" title="传统的面向DAG图的优化，代码&#x2F;计算层面的优化"></a>传统的面向DAG图的优化，代码&#x2F;计算层面的优化</h2><h3 id="常量折叠"><a href="#常量折叠" class="headerlink" title="常量折叠"></a>常量折叠</h3><h4 id="传统编译器中的常量折叠、传播"><a href="#传统编译器中的常量折叠、传播" class="headerlink" title="传统编译器中的常量折叠、传播"></a>传统编译器中的常量折叠、传播</h4><p><strong>Constant folding，常量折叠，通过对编译时的常量或常量表达式进行计算来简化代码。</strong></p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">i = <span class="number">320</span>*<span class="number">200</span>*<span class="number">32</span>;</span><br></pre></td></tr></table></figure>
<p>类似这样的常量表达式，在编译过程中编译器就把这个表达式的值算出来，从而在真正执行时减少内存读取（三次）以及指令相乘（两次）操作。</p>
<figure class="highlight x86asm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">%a: load <span class="number">320</span></span><br><span class="line">%b: load <span class="number">200</span></span><br><span class="line">%x: <span class="keyword">mul</span> %a, %b</span><br><span class="line">%c: load <span class="number">32</span></span><br><span class="line">%y: <span class="keyword">mul</span> %x %c</span><br><span class="line"></span><br><span class="line">%a: load <span class="number">2048000</span></span><br></pre></td></tr></table></figure>

<p><strong>constant propagation，常量传播，通过将表达式中的常量替换为相关表达式或字面量，再使用常量折叠技术来简化代码。</strong></p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">def <span class="title">foo</span><span class="params">()</span>:</span></span><br><span class="line"><span class="function">    x =</span> <span class="number">14</span>;</span><br><span class="line">    y = <span class="number">7</span> - x / <span class="number">2</span>;</span><br><span class="line">    <span class="keyword">return</span> y * (<span class="number">28</span> / x + <span class="number">2</span>);</span><br><span class="line"><span class="comment">// 在编译阶段编译器可以将x的值向下传播，</span></span><br><span class="line"><span class="comment">// 然后编译器可以将y的值提前算出来，然后再传播，</span></span><br><span class="line"><span class="comment">// 可以将return的值也算出来。类似如下</span></span><br><span class="line"><span class="function">def <span class="title">foo</span><span class="params">()</span>:</span></span><br><span class="line"><span class="function">    x =</span> <span class="number">14</span>;</span><br><span class="line">    y = <span class="number">7</span> - <span class="number">14</span> / <span class="number">2</span>;</span><br><span class="line">    <span class="keyword">return</span> y * (<span class="number">28</span> / <span class="number">14</span> + <span class="number">2</span>);</span><br></pre></td></tr></table></figure>

<h4 id="AI编译器中的常量折叠"><a href="#AI编译器中的常量折叠" class="headerlink" title="AI编译器中的常量折叠"></a>AI编译器中的常量折叠</h4><p><strong>在AI编译器中，常量折叠是将计算图中可以预先确定输出值的节点替换成常量，并对计算图进行一些结构简化的操作。示例如下</strong></p>
<ul>
<li>AddN（与传统编译器中的常量折叠类似）<br>  对于形状大小相同的两个常量tensor，add的结果同样是一个常量。那么AI编译器就可以将其提前计算出来，不需要在真正执行过程中再给这个Add节点分配额外的存储资源，也不需要重复计算，可直接访问其结果。</li>
<li>BN折叠<br>  这种情况说的是Conv之后接的BN，在编译过程中AI编译器会将BN合并进Conv中。BN的参数均值、方差、Gamma和Beta在推理过程中全部已知。此时就用常量传播+常量折叠将其参数合并进Conv的weight和bias中。<strong>需要注意的是与算子融合并不一样，我认为可以将其理解成算子融合的前一步，将BN折叠进Conv后再融合后续的类似ReLU进Conv。</strong></li>
</ul>
<p><strong>AI编译器中常量折叠方法</strong></p>
<ol>
<li>传统编译器中的常量折叠，找到输入节点均为常量的节点，提前计算该节点的值来完整替换该节点。</li>
<li>常量折叠与数据形状shape有关系，通过计算图已有信息推断出形状结果，用来代替原来的节点。常量折叠不仅仅用来算数字，还经常用来提前算出张量的形状信息，这个方法可以叫形状上的常量折叠，比如concat在拼接的时候，输入的两个数据（举例）形状太小已知，那么就可以在编译阶段提前算出concat之后的shape，若两个数据也已知，就可以将其结果也计算出来。</li>
<li>常量折叠与已知常量的代数化简有关。例如上面提到的BN折叠。<br>举例，TensorFlow常量折叠PASS的流程。<ol>
<li>先处理shape、size、rank这三类运算节点，其输出都取决于输入tensor的形状，而与具体的输入取值无关，所以输出可提前计算出来。</li>
<li>将上述三类运算节点的输出提前计算出，将节点替换为Const节点，方便后续常量折叠和替换。</li>
<li>折叠计算图操作：基于常量折叠的规则，遍历计算图，不断地用常量节点替换计算图中节点，直到没有任何可以替换的节点为止。</li>
<li>处理sum、prod、min、max、mean、any、all着几类运算节点，其共同点是都沿着输入tensor的维度做一定的计算。将符合一定条件的这类节点替换为Identity节点（占位符节点）。</li>
</ol>
</li>
</ol>
<p><strong>在具体实现过程中，更重要的是发现类似于BN折叠的规则。</strong></p>
<h3 id="公共子表达式消除-CSE"><a href="#公共子表达式消除-CSE" class="headerlink" title="公共子表达式消除-CSE"></a>公共子表达式消除-CSE</h3><h4 id="传统编译器中的CSE，LLVM将其定义为一个PASS"><a href="#传统编译器中的CSE，LLVM将其定义为一个PASS" class="headerlink" title="传统编译器中的CSE，LLVM将其定义为一个PASS"></a>传统编译器中的CSE，LLVM将其定义为一个PASS</h4><p><strong>在执行这项优化过程中，编译器会视情况将多个相同的表达式替换成一个变量，该变量存储计算该表达式后所得的值。视情况的意思就是编译器会评估重复计算开销以及存储表达式结果开销。示例如下：</strong></p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">a = b * c + g;</span><br><span class="line">d = b * c + e;</span><br><span class="line"><span class="comment">// 在编译过程中，编译器会将 b * c替换成一个变量</span></span><br><span class="line">temp = b * c;</span><br><span class="line">a = temp + g;</span><br><span class="line">d = temp + e;</span><br></pre></td></tr></table></figure>
<p><strong>principle，基本原则：</strong>基于表达式的定义可达性。当以下条件成立时，一个表达式 b * c 在程序的某个点p被定义为可达的。</p>
<ol>
<li>从初始节点到点p的每条路径在到达p之前计算过 b * c；</li>
<li>b * c 被计算后，不论b或者c到达p以前都没有被重新赋值过；<br>编译器开发者将公共子表达式消除分为两种：</li>
</ol>
<ul>
<li>本地公共子表达式消除：工作在基本块之内（LLVM 中提到的BasicBlock概念）。</li>
<li>全局公共子表达式消除：工作在整个过程之中。<br><strong>Algorithm</strong>，对于语句 %S : z &#x3D; x op y,若x op y在语句s之前可用，则：</li>
</ul>
<ol>
<li>从s开始逆向搜索IR，找到举例s最近执行w &#x3D; x op y的语句</li>
<li>建立临时变量 %u</li>
<li>把步骤1中找到的语句 w &#x3D; x op y进行替换。<code>%u = x op y, %w = u</code></li>
<li>使用z &#x3D; u替换s，重复步骤1知道遍历完IR。</li>
</ol>
<h4 id="AI编译器中的CSE"><a href="#AI编译器中的CSE" class="headerlink" title="AI编译器中的CSE"></a>AI编译器中的CSE</h4><p><strong>从传统编译器中搜索相同的子表达式，转变成了在计算图中搜索相同结构的子图。</strong><a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1rv4y1Q7tp?t=324.1">图片取自ZOMI大佬</a><br><img src="/assets/AIcompiler_CSE.png" alt="AIcompiler_CSE" width="700"></p>
<p><strong>具体实现，粗略说明。</strong>，通过遍历计算图，建立候选哈希表map，记录已处理过的同一种类型的OP。输入：计算图Graph IR（找到公共子表达式并优化计算图）。</p>
<ol>
<li>获取逆后续节点集Set：对计算图Graph IR进行深度优化遍历DFS，将结果逆转得到逆后续节点集（从某个节点出发，沿着计算图能够到达的节点的集合）。逆后续得到的结果是拓扑排序，即访问某一个节点时，该节点的依赖节点都已经被访问。</li>
<li>创建Map：存储公共子表达式候选集，遍历Set时，可以从Map中查找是否由可使用的表达式。</li>
<li>遍历计算图的所有节点，判断是否由公共子表达式：获取节点hash值，hash的key由输出个数+输出类型s+输入接待你id组成，key可以保证输入+输出个数+类型都相同时，得到的hash值相同。达到检索公共表达式的目的。</li>
<li>记录入候选集Map中：根据hash值从Map中得到候选集，当候选集为空，即第一次遇到这样的表达式时将节点Node存入Map中。</li>
<li>判断可复用的公共子表达式：候选集非空，说明之前遍历到了类似的表达式，进一步判断是否可复用已保存节点表达式的结果。节点的输入都是来自相同Const常量节点，可以保证输入数据完全相同；输出个数和类型相同，可以保证输出结果相同；满足条件即可复用之前保存的节点的结果。</li>
<li>删除重复节点：判断表达式可以复用后，要将重复节点删除，但是主要要把上一个节点和下一个节点连起来，保证计算图的完整。</li>
</ol>
<h3 id="死代码消除-DEC"><a href="#死代码消除-DEC" class="headerlink" title="死代码消除-DEC"></a>死代码消除-DEC</h3><h4 id="传统编译器中死代码消除"><a href="#传统编译器中死代码消除" class="headerlink" title="传统编译器中死代码消除"></a>传统编译器中死代码消除</h4><p><strong>移除对程序执行结果没有任何影响的代码。死代码消除最普遍的做法，是通过预处理器来判断代码是否需要被编译，就是说通过代入一个数值来决定程序带是否该被编译。示例如下</strong></p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">int</span> <span class="title">foo</span><span class="params">(<span class="type">void</span>)</span></span>&#123;</span><br><span class="line">    <span class="type">int</span> a = <span class="number">24</span>;</span><br><span class="line">    <span class="type">int</span> b = <span class="number">25</span>; <span class="comment">// return 之前用不到</span></span><br><span class="line">    <span class="type">int</span> c;</span><br><span class="line">    c = a &lt;&lt; <span class="number">2</span>;</span><br><span class="line">    <span class="keyword">return</span> c; <span class="comment">// 这行之后的代码不会被执行</span></span><br><span class="line">    b = <span class="number">24</span>;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><strong>优点：</strong></p>
<ul>
<li>避免执行不必要的操作，提高运行效率，减小运行时间。</li>
<li>节省不必要的资源分配优化空间。</li>
<li>减小代码长度，增加可读性。</li>
</ul>
<h4 id="AI编译器中的死代码消除"><a href="#AI编译器中的死代码消除" class="headerlink" title="AI编译器中的死代码消除"></a>AI编译器中的死代码消除</h4><ul>
<li>AI编译器中死代码消除可优化计算图的计算和存储效率，避免为死节点分配存储空间和进行计算。</li>
<li>死代码在定义神经网络模型时通常不会存在，一般来说是其他图优化Pass造成的死代码。因此死代码消除Pass通常在其他的图优化Pass之后进行。</li>
</ul>
<p><a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1hD4y1h7nh?t=266.5">图片取自ZOMI大佬</a>。训练过程会产生很多额外的子图，推理时需删除。反向图也需删除，以及一些无用的控制流也会被删除。<br><img src="/assets/AIcompiler_DCE.png" alt="AIcompiler_DCE" width="700"></p>
<p>Algorithm，粗略解释：</p>
<ol>
<li>获取逆后续节点集Set，对计算图 Graph IR进行深度优先遍历DFS，将结果逆转得到逆后续节点集。</li>
<li>遍历逆后续节点集，判断是否为死节点：获取节点的输出值，判断是否为计算图的输出节点，若不是且无对应输出节点，则为死节点。</li>
<li>删除死节点，重新遍历计算图：删除死节点，注意死节点删除后还需删除对应输入到死节点的边。然后重复步骤1。</li>
</ol>
<h3 id="代数简化-Algebraic-Reduced"><a href="#代数简化-Algebraic-Reduced" class="headerlink" title="代数简化 Algebraic Reduced"></a>代数简化 Algebraic Reduced</h3><h4 id="算术化简"><a href="#算术化简" class="headerlink" title="算术化简"></a>算术化简</h4><p><strong>利用交换律、结合律、提取公因式、分配律化简等规律调整计算图中算子的执行顺序，或者删除不必要的算子，以提高图整体的计算效率。</strong> 实现上的一个通用逻辑是通过子图替换方式实现。第一种方式就是抽象出一套通用的子图替换框架，在对各规则实例化。第二种方式是针对每一个规则实现专门的优化逻辑。重点是发现规则发现规律。<a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1g24y1Q7qC?t=365.2">图片取自ZOMI大佬</a><br><img src="/assets/AIcompiler_代数化简.png" alt="AIcompiler_代数化简" width="700"></p>
<h4 id="运行化简"><a href="#运行化简" class="headerlink" title="运行化简"></a>运行化简</h4><p><strong>减少运行时冗余的算子或算子对。</strong></p>
<ul>
<li>对合算子化简：就比如由连续两个转置、取反、倒数、逻辑非等操作，就可以将这两个算子化简掉。</li>
<li>幂等算子化简：就比如连续的多个reshape，可以化简成一个reshape</li>
</ul>
<h4 id="广播化简（broadcast）"><a href="#广播化简（broadcast）" class="headerlink" title="广播化简（broadcast）"></a>广播化简（broadcast）</h4><p><strong>多个张量形状shape不同，需要进行广播将张量的形状拓展为相同shape再进行计算，化简为最小计算所需的广播运算数量。示例如下，</strong><a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1g24y1Q7qC?t=500.2">图片取自ZOMI大佬</a><br><img src="/assets/AIcompiler_广播化简.png" alt="AIcompiler_广播化简" width="700"></p>
<p>这张图简单的说明了使用位置替换实现广播化简，最小化广播次数。通过将S1和S2先相加，再进行broadcast拓展形状，用一次向量的相加替换了一次broadcast。最终计算图仍然是三次相加，但是只有一次broadcast了。</p>
<h2 id="前端优化总结"><a href="#前端优化总结" class="headerlink" title="前端优化总结"></a>前端优化总结</h2><p>大致的一个前端优化Pass的排序，实际工程中也会有所不同。首先进行面向图层的优化，即神经网络相关的优化。<strong>算子融合 - - -&gt; 算子替换 - - -&gt; 布局转换 - - -&gt; 内存分配</strong>。然后进行面向DAG图的优化，即代码&#x2F;计算层面的优化。<strong>常量折叠 - - -&gt; 公共子表达式消除 - - -&gt; 死代码消除（死节点消除） - - -&gt; 代数简化</strong>。</p>
<h1 id="后端优化"><a href="#后端优化" class="headerlink" title="后端优化"></a>后端优化</h1><ul>
<li>特定硬件的优化，获取高性能的代码<ol>
<li>将 Low-level IR 转换为 LLVM IR ，利用LLVM基础结构生成优化的CPU&#x2F;GPU代码</li>
<li>对特定硬件做针对性的优化。</li>
</ol>
</li>
<li>自动调整，在特定硬件优化中用于参数调整的搜索空间巨大（比如对张量、数据进行切分，数据如何排布），需要利用自动调整来确定最佳参数设置。<ol>
<li>利用 Halide&#x2F;TVM 使用的方式，利用机器学习去做搜索优化。其允许调度和计算表达分开。</li>
<li>利用多面体模型 poly model进行参数调整</li>
</ol>
</li>
<li>优化内核库，厂商特定的优化内核库。因为经过了一些特定的优化，可能会比编译器生成的算子效率更高。</li>
</ul>
<h2 id="后端优化概念"><a href="#后端优化概念" class="headerlink" title="后端优化概念"></a>后端优化概念</h2><p>将计算图转换为低级的IR，关注算子节点内部的具体实现，针对具体硬件使其性能达到最佳。<a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV17D4y177bP?t=242.5">图片取自ZOMI大佬</a><br><img src="/assets/AIcompiler_后端优化.png" alt="AIcompiler_后端优化" width="700"></p>
<ol>
<li>生成低级IR：不同AI编译器内部低级IR形式和定义不同，但是对于同一算子，算法的原理实质相同。对于具体的算子，需要用AI编译器底层的接口来定义算法，再由编译器来生成内部的低级IR。</li>
<li>后端优化：针对不同的架构，不同算法的实现方式由不同的性能，后端优化的目的就是要找到算子的最优实现方式，达到最优性能。同一算子的不同形态都会有不同的循环优化方法。</li>
<li>代码生成：对优化后的低级IR转换成更低级的IR，然后再转化为机器指令执行。非AI编译器核心内容。<br><strong>question</strong>后端优化为什么不直接用传统的通用编译器，如GCC、LLVM？</li>
</ol>
<ul>
<li>深度学习中主要数据为张量，传统编译器不擅长对张量计算进行优化。</li>
<li>通用编译器主要针对通用编程语言，缺少领域特定语言DSL支持，以及相关的优化。</li>
</ul>
<h3 id="算子分类"><a href="#算子分类" class="headerlink" title="算子分类"></a>算子分类</h3><p>判断依据：算子的FLOPS&#x2F;数据访问量大于还是小于1。</p>
<ul>
<li>访存密集型（操作简单，但需访问整个张量）：计算量相对较低，但需要频繁访问内存。性能瓶颈主要再内存带宽，而不是算力，这类算子通常需要考虑内存访问优化、数据复用、缓存优化。比如Element-wise型算子、只做数据搬运的算子、标准化算子等。</li>
<li>计算密集型（操作复杂，计算量大）：计算量大，远远高于访问内存的量。性能瓶颈收硬件算力限制。这类算子通常要关注算力调度、向量化、并行化。比如卷积、矩阵乘、注意力等。</li>
</ul>
<h3 id="算子优化遇到的问题"><a href="#算子优化遇到的问题" class="headerlink" title="算子优化遇到的问题"></a>算子优化遇到的问题</h3><ol>
<li>优化手段多样：再不同情况下权衡优化及其对应参数，对于优化专家来说也是相当耗费精力的。</li>
<li>通用性与移植性：不同类型的硬件架构差异，使优化方法要考虑的因素也有很大不同。</li>
<li>优化间相互影响：各种优化之间可能会相互制约，相互影响。这意味着最优的优化方法组合与序列是一个困难的组合优化问题，甚至是NP问题</li>
</ol>
<h3 id="算子库"><a href="#算子库" class="headerlink" title="算子库"></a>算子库</h3><p>针对两类算子进行优化，实现其逻辑不难，但要结合硬件能力达到高性能就比较难了，更不要说要达到极致的性能。业界最为常见的方式是将预置的算子实现封装成计算库。如CuDNN、CuBLAS、OpenBLAS、Eigen等优秀的计算库。</p>
<p><strong>question</strong></p>
<ol>
<li>如何应对AI领域算子迭代更新快？<ul>
<li>将算子按通用类别抽象，不去针对每个具体算子写优化。每一类的算子定义其行为规范、输入输出规则、可优化模式，若心酸子属于某类，则自动继承已有的优化逻辑。</li>
<li>插件化的算子注册。新算子能以插件或注册表形式动态添加，经典算子可以在编译器中硬编码，也可以和新算子一样的方式。用户提供算子定义、验证逻辑等，编译器通过注册机制自动识别算子，并加入优化流程。</li>
<li>DSL&#x2F;MLIR分层设计，用高级描述语言DSL或MLIR Dialect描述算子逻辑，优化和后端生成独立。<br> 这样做新算子只需要写IR逻辑，共享优化Pass。</li>
</ul>
</li>
<li>如何解决统一算子在多平台移植后一致性的问题？<ul>
<li>统一算子抽象+标准算法实现+精度规范+完整的测试验证</li>
</ul>
</li>
<li>如何面对算子组合爆炸问题？如参数多样，融合大算子等。<ul>
<li>模式化+启发式+搜索约束+模板化+自动调度</li>
</ul>
</li>
</ol>
<p>自动化生成，通过自动kernel生成的方式，对于给定算法自动生成目标平台上的高性能实现。自动化生成大致分为两个方向：1. AI编译器融合机器学习方法，Auto Tuning（TVM）。2. 算子计算加速用编译技术解决，Polyhedral。</p>
<h2 id="算子执行与调度"><a href="#算子执行与调度" class="headerlink" title="算子执行与调度"></a>算子执行与调度</h2><h2 id="算子循环优化"><a href="#算子循环优化" class="headerlink" title="算子循环优化"></a>算子循环优化</h2><h2 id="Auto-Tuning"><a href="#Auto-Tuning" class="headerlink" title="Auto-Tuning"></a>Auto-Tuning</h2><h2 id="Polyhedral"><a href="#Polyhedral" class="headerlink" title="Polyhedral"></a>Polyhedral</h2><h1 id="AI编译器中比较难解决的问题"><a href="#AI编译器中比较难解决的问题" class="headerlink" title="AI编译器中比较难解决的问题"></a>AI编译器中比较难解决的问题</h1><ol>
<li>动态shape问题<ul>
<li>现阶段主流的AI编译器主要针对特定的静态shape输入完成编译优化，对于包含控制流的动态计算图提供的支持有限</li>
<li>在NLP任务中，输入序列的长度是不固定的，会存在大量的动态shape需求。这时候需要前端将计算图改写为静态计算图，或者只优化适合编译器的部分。</li>
<li>部分任务很难通过人工来改写成静态化计算图。</li>
</ul>
</li>
<li>Python编译静态化问题，将动态图转为静态图目前来说大部分是通过<code>torch.jit.trace()</code>去做的，导出onnx就是在做<code>torch.jit.trace()</code>。<ul>
<li>类型推导：有python动态类型转换到编译器的静态类型，遇到的问题就是静态类型不一定能够表达所有的动态类型。</li>
<li>控制流的表达，if、else、while、for等。在<code>torch.jit.trace()</code>时候的一个条件就是不能有类似的控制流。</li>
<li>JIT的编译性能，会增加额外的编译开销，有编译肯定会损失性能。<br> <strong>就比如我之前在复旦微的ai芯片上做的一个项目，pytorch中定义的某些算子，在导出静态图的时候，需要做替换，用静态去表达动态，这个时候就会出现性能损失。</strong></li>
</ul>
</li>
<li>如何通过AI编译器压榨硬件性能，特别是DSA类芯片。编译器在性能优化的难度和复杂度上的难度变大。<ul>
<li>难度，性能优化依赖图算融合优化。独立优化无法充分发挥芯片性能，需要例如子图切分、子图内垂直融合优化和水平并行加速等。</li>
<li>复杂度随着硬件的复杂度提升而提升，标量+向量+张量+加速指令、多级的存储结构，导致 kernel 实现 schedule、tilling、vectorization、tensorization 复杂</li>
</ul>
</li>
<li>处理神经网络特性：自动微分、自动并行等<ul>
<li>自动并行，大模型训练遇到内存墙性能墙等问题需要并行策略来解决。<ul>
<li>Scale out(多维混合并行能力，数据、张量、流水线并行)，Scale up（重计算、混合精度、异构并行）。二者最大的挑战就是效率墙。</li>
</ul>
</li>
<li>面向HPC场景自动微分的要求更高。</li>
</ul>
</li>
<li>如何平衡易用性和性能</li>
</ol>
<p><strong>question</strong></p>
<ul>
<li>图算能否统一表达，统一编译优化，形成更通用的AI编译器？</li>
<li>完全的自动并行是否可行？</li>
<li>AI芯片需要编译器么？需要AI编译器么？</li>
</ul>
<p><strong>future</strong></p>
<ol>
<li>编译器分开推理和训练，AOT和JIT两种编译方式并存</li>
<li>IR形态，需要有类似MLIR对AI统一的IR表达</li>
<li>自动并行、自动微分</li>
<li>kernel 自动生成，降低开发门槛，快速的实现高效和高泛化的算子</li>
</ol>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.8/dist/katex.min.css">
</article>
<div class="article-footer">
    <section id="license">
      <div class="header"><span>许可协议</span></div>
      <div class="body"><p>本文采用 <a target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">署名-非商业性使用-相同方式共享 4.0 国际</a> 许可协议，转载请注明出处。</p>
</div>
    </section>
    


    <section id="share">
      <div class="header"><span>分享文章</span></div>
      <div class="body">
        <div class="link"><input class="copy-area" readonly="true" id="copy-link" value="https://maskmask15.github.io/2025/09/25/AI%E7%BC%96%E8%AF%91%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%9501/" /></div>
        <div class="social-wrap dis-select"><a class="social share-item wechat" onclick="util.toggle(&quot;qrcode-wechat&quot;)"><img  src="https://gcore.jsdelivr.net/gh/cdn-x/placeholder@1.0.12/social/b32ef3da1162a.svg" /></a><a class="social share-item weibo" target="_blank" rel="external nofollow noopener noreferrer" href="https://service.weibo.com/share/share.php?url=https://maskmask15.github.io/2025/09/25/AI%E7%BC%96%E8%AF%91%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%9501/&title=AI编译器学习记录 01 - LuYh&summary=AI编译器学习记录 01"><img  src="https://gcore.jsdelivr.net/gh/cdn-x/placeholder@1.0.12/social/80c07e4dbb303.svg" /></a><a class="social share-item email" href="mailto:?subject=AI编译器学习记录 01 - LuYh&amp;body=https://maskmask15.github.io/2025/09/25/AI%E7%BC%96%E8%AF%91%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%9501/"><img  src="https://gcore.jsdelivr.net/gh/cdn-x/placeholder@1.0.12/social/a1b00e20f425d.svg" /></a><a class="social share-item link" onclick="util.copy(&quot;copy-link&quot;, &quot;复制成功&quot;)"><img  src="https://gcore.jsdelivr.net/gh/cdn-x/placeholder@1.0.12/social/8411ed322ced6.svg" /></a></div>
        
        <div class="qrcode" id="qrcode-wechat" style="opacity:0;height:0">
          <img src="https://api.qrserver.com/v1/create-qr-code/?size=256x256&data=https://maskmask15.github.io/2025/09/25/AI%E7%BC%96%E8%AF%91%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%9501/"/>
        </div>
        
      </div>
    </section>
    </div>

<div class="related-wrap" id="read-next"><section class="body"><div class="item" id="prev"></div><div class="item" id="next"><div class="note">较早文章</div><a href="/2025/09/24/LLVM%E5%AD%A6%E4%B9%A002/">LLVM 学习记录 0x</a></div></section></div>






<footer class="page-footer footnote"><hr><div class="text"><p>本站由 <a href="/">LuYhhhhh</a> 使用 <a target="_blank" rel="noopener" href="https://github.com/xaoxuu/hexo-theme-stellar/tree/1.32.4">Stellar 1.32.4</a> 主题创建。<br>本博客所有文章除特别声明外，均采用 <a target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a> 许可协议，转载请注明出处。</p>
</div></footer>
<div class="main-mask" onclick="sidebar.dismiss()"></div></div><aside class="l_right">
<div class="widgets">



<widget class="widget-wrapper toc" id="data-toc" collapse="false"><div class="widget-header dis-select"><span class="name">本文目录</span><a class="cap-action" onclick="sidebar.toggleTOC()" ><svg xmlns="http://www.w3.org/2000/svg" width="32" height="32" viewBox="0 0 24 24"><path fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M10 6h11m-11 6h11m-11 6h11M4 6h1v4m-1 0h2m0 8H4c0-1 2-2 2-3s-1-1.5-2-1"/></svg></a></div><div class="widget-body"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#AI%E7%BC%96%E8%AF%91%E5%99%A8%E5%8F%91%E5%B1%95%E8%BF%87%E7%A8%8B"><span class="toc-text">AI编译器发展过程</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#AI%E7%BC%96%E8%AF%91%E5%99%A8%E7%9A%84%E9%80%9A%E7%94%A8%E6%9E%B6%E6%9E%84"><span class="toc-text">AI编译器的通用架构</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#IR"><span class="toc-text">IR</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%89%8D%E5%90%8E%E7%AB%AF%E4%BC%98%E5%8C%96%E5%8C%BA%E5%88%AB"><span class="toc-text">前后端优化区别</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%89%8D%E7%AB%AF%E4%BC%98%E5%8C%96"><span class="toc-text">前端优化</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%9C%9F%E6%AD%A3%E7%9A%84%E9%9D%A2%E5%90%91%E5%9B%BE%E5%B1%82%E7%9A%84%E4%BC%98%E5%8C%96%EF%BC%8C%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9B%B8%E5%85%B3%E7%9A%84%E4%BC%98%E5%8C%96"><span class="toc-text">真正的面向图层的优化，神经网络相关的优化</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%AE%97%E5%AD%90%E8%9E%8D%E5%90%88-OPFusion"><span class="toc-text">算子融合 OPFusion</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%B8%83%E5%B1%80%E8%BD%AC%E6%8D%A2-Layout-Transform"><span class="toc-text">布局转换 Layout Transform</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%BC%A0%E9%87%8F%E6%95%B0%E6%8D%AE%E5%B8%83%E5%B1%80"><span class="toc-text">张量数据布局</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#NCHW%E4%B8%8ENHWC"><span class="toc-text">NCHW与NHWC</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#AI%E7%BC%96%E8%AF%91%E5%B8%83%E5%B1%80%E8%BD%AC%E6%8D%A2%E4%BC%98%E5%8C%96"><span class="toc-text">AI编译布局转换优化</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D-%E4%BC%98%E5%8C%96"><span class="toc-text">内存分配&#x2F;优化</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%86%85%E5%AD%98%E5%88%92%E5%88%86"><span class="toc-text">内存划分</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%86%85%E5%AD%98%E4%BC%98%E5%8C%96%E6%96%B9%E6%B3%95%E3%80%82%EF%BC%88%E6%B2%A1%E6%9C%89%E6%8F%90%E5%88%B0%E6%9D%83%E9%87%8D%E5%A4%8D%E7%94%A8%EF%BC%8C%E8%BE%93%E5%85%A5%E5%A4%8D%E7%94%A8%EF%BC%8C%E8%BE%93%E5%87%BA%E5%A4%8D%E7%94%A8%EF%BC%8C%E5%8F%AF%E8%83%BD%E8%BF%99%E7%A7%8D%E6%9B%B4%E5%87%86%E7%A1%AE%E5%9C%B0%E8%AF%B4%E5%B1%9E%E4%BA%8E%E6%95%B0%E6%8D%AE%E5%A4%8D%E7%94%A8%EF%BC%8C%E6%95%B0%E6%8D%AE%E6%B5%81%E6%88%96%E8%80%85%E5%AD%98%E5%8F%96%E6%96%B9%E5%BC%8F%E4%B8%8A%E7%9A%84%E4%BC%98%E5%8C%96%EF%BC%89"><span class="toc-text">内存优化方法。（没有提到权重复用，输入复用，输出复用，可能这种更准确地说属于数据复用，数据流或者存取方式上的优化）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%86%85%E5%AD%98%E5%A4%8D%E7%94%A8%EF%BC%88%E9%87%8D%E7%82%B9%EF%BC%89"><span class="toc-text">内存复用（重点）</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BC%A0%E7%BB%9F%E7%9A%84%E9%9D%A2%E5%90%91DAG%E5%9B%BE%E7%9A%84%E4%BC%98%E5%8C%96%EF%BC%8C%E4%BB%A3%E7%A0%81-%E8%AE%A1%E7%AE%97%E5%B1%82%E9%9D%A2%E7%9A%84%E4%BC%98%E5%8C%96"><span class="toc-text">传统的面向DAG图的优化，代码&#x2F;计算层面的优化</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%B8%B8%E9%87%8F%E6%8A%98%E5%8F%A0"><span class="toc-text">常量折叠</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BC%A0%E7%BB%9F%E7%BC%96%E8%AF%91%E5%99%A8%E4%B8%AD%E7%9A%84%E5%B8%B8%E9%87%8F%E6%8A%98%E5%8F%A0%E3%80%81%E4%BC%A0%E6%92%AD"><span class="toc-text">传统编译器中的常量折叠、传播</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#AI%E7%BC%96%E8%AF%91%E5%99%A8%E4%B8%AD%E7%9A%84%E5%B8%B8%E9%87%8F%E6%8A%98%E5%8F%A0"><span class="toc-text">AI编译器中的常量折叠</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%85%AC%E5%85%B1%E5%AD%90%E8%A1%A8%E8%BE%BE%E5%BC%8F%E6%B6%88%E9%99%A4-CSE"><span class="toc-text">公共子表达式消除-CSE</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BC%A0%E7%BB%9F%E7%BC%96%E8%AF%91%E5%99%A8%E4%B8%AD%E7%9A%84CSE%EF%BC%8CLLVM%E5%B0%86%E5%85%B6%E5%AE%9A%E4%B9%89%E4%B8%BA%E4%B8%80%E4%B8%AAPASS"><span class="toc-text">传统编译器中的CSE，LLVM将其定义为一个PASS</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#AI%E7%BC%96%E8%AF%91%E5%99%A8%E4%B8%AD%E7%9A%84CSE"><span class="toc-text">AI编译器中的CSE</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%AD%BB%E4%BB%A3%E7%A0%81%E6%B6%88%E9%99%A4-DEC"><span class="toc-text">死代码消除-DEC</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BC%A0%E7%BB%9F%E7%BC%96%E8%AF%91%E5%99%A8%E4%B8%AD%E6%AD%BB%E4%BB%A3%E7%A0%81%E6%B6%88%E9%99%A4"><span class="toc-text">传统编译器中死代码消除</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#AI%E7%BC%96%E8%AF%91%E5%99%A8%E4%B8%AD%E7%9A%84%E6%AD%BB%E4%BB%A3%E7%A0%81%E6%B6%88%E9%99%A4"><span class="toc-text">AI编译器中的死代码消除</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BB%A3%E6%95%B0%E7%AE%80%E5%8C%96-Algebraic-Reduced"><span class="toc-text">代数简化 Algebraic Reduced</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%AE%97%E6%9C%AF%E5%8C%96%E7%AE%80"><span class="toc-text">算术化简</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%BF%90%E8%A1%8C%E5%8C%96%E7%AE%80"><span class="toc-text">运行化简</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%B9%BF%E6%92%AD%E5%8C%96%E7%AE%80%EF%BC%88broadcast%EF%BC%89"><span class="toc-text">广播化简（broadcast）</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%89%8D%E7%AB%AF%E4%BC%98%E5%8C%96%E6%80%BB%E7%BB%93"><span class="toc-text">前端优化总结</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%90%8E%E7%AB%AF%E4%BC%98%E5%8C%96"><span class="toc-text">后端优化</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%90%8E%E7%AB%AF%E4%BC%98%E5%8C%96%E6%A6%82%E5%BF%B5"><span class="toc-text">后端优化概念</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%AE%97%E5%AD%90%E5%88%86%E7%B1%BB"><span class="toc-text">算子分类</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%AE%97%E5%AD%90%E4%BC%98%E5%8C%96%E9%81%87%E5%88%B0%E7%9A%84%E9%97%AE%E9%A2%98"><span class="toc-text">算子优化遇到的问题</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%AE%97%E5%AD%90%E5%BA%93"><span class="toc-text">算子库</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%AE%97%E5%AD%90%E6%89%A7%E8%A1%8C%E4%B8%8E%E8%B0%83%E5%BA%A6"><span class="toc-text">算子执行与调度</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%AE%97%E5%AD%90%E5%BE%AA%E7%8E%AF%E4%BC%98%E5%8C%96"><span class="toc-text">算子循环优化</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Auto-Tuning"><span class="toc-text">Auto-Tuning</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Polyhedral"><span class="toc-text">Polyhedral</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#AI%E7%BC%96%E8%AF%91%E5%99%A8%E4%B8%AD%E6%AF%94%E8%BE%83%E9%9A%BE%E8%A7%A3%E5%86%B3%E7%9A%84%E9%97%AE%E9%A2%98"><span class="toc-text">AI编译器中比较难解决的问题</span></a></li></ol></div><div class="widget-footer"><a class="top" onclick="util.scrollTop()"><svg xmlns="http://www.w3.org/2000/svg" width="32" height="32" viewBox="0 0 24 24"><!-- Icon from Solar by 480 Design - https://creativecommons.org/licenses/by/4.0/ --><g fill="none" stroke="currentColor" stroke-linecap="round" stroke-width="1.5"><path stroke-linejoin="round" d="m9 15.5l3-3l3 3m-6-4l3-3l3 3"/><path d="M7 3.338A9.95 9.95 0 0 1 12 2c5.523 0 10 4.477 10 10s-4.477 10-10 10S2 17.523 2 12c0-1.821.487-3.53 1.338-5"/></g></svg><span>回到顶部</span></a></div></widget>
</div></aside><div class='float-panel'>
  <button type='button' style='display:none' class='laptop-only rightbar-toggle mobile' onclick='sidebar.rightbar()'>
    <svg xmlns="http://www.w3.org/2000/svg" width="32" height="32" viewBox="0 0 24 24"><path fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M10 6h11m-11 6h11m-11 6h11M4 6h1v4m-1 0h2m0 8H4c0-1 2-2 2-3s-1-1.5-2-1"/></svg>
  </button>
  <button type='button' style='display:none' class='mobile-only leftbar-toggle mobile' onclick='sidebar.leftbar()'>
    <svg xmlns="http://www.w3.org/2000/svg" width="32" height="32" viewBox="0 0 24 24"><g fill="none" stroke="currentColor" stroke-width="1.5"><path d="M2 11c0-3.771 0-5.657 1.172-6.828C4.343 3 6.229 3 10 3h4c3.771 0 5.657 0 6.828 1.172C22 5.343 22 7.229 22 11v2c0 3.771 0 5.657-1.172 6.828C19.657 21 17.771 21 14 21h-4c-3.771 0-5.657 0-6.828-1.172C2 18.657 2 16.771 2 13z"/><path id="sep" stroke-linecap="round" d="M5.5 10h6m-5 4h4m4.5 7V3"/></g></svg>
  </button>
</div>
</div><div class="scripts">


<script type="text/javascript">
  window.canonical = {"originalHost":null,"officialHosts":["localhost"],"encoded":""};
  const ctx = {
    date_suffix: {
      just: `刚刚`,
      min: `分钟前`,
      hour: `小时前`,
      day: `天前`,
    },
    root : `/`,
    tag_plugins: {
      chat: Object.assign({"api":"https://siteinfo.listentothewind.cn/api/v1"}),
    }
  };

  // required plugins (only load if needs)
  if (`local_search`) {
    ctx.search = {};
    ctx.search.service = `local_search`;
    if (ctx.search.service == 'local_search') {
      let service_obj = Object.assign({}, `{"field":"all","path":"/search.json","content":true,"skip_search":null,"sort":"-date"}`);
      ctx.search[ctx.search.service] = service_obj;
    }
  }
  const def = {
    avatar: `https://gcore.jsdelivr.net/gh/cdn-x/placeholder@1.0.12/avatar/round/3442075.svg`,
    cover: `https://gcore.jsdelivr.net/gh/cdn-x/placeholder@1.0.12/cover/76b86c0226ffd.svg`,
    loading: `https://api.iconify.design/eos-icons:three-dots-loading.svg?color=%231cd0fd`,
  };
  const deps = {
    jquery: `https://gcore.jsdelivr.net/npm/jquery@3.7/dist/jquery.min.js`,
    marked: `https://gcore.jsdelivr.net/npm/marked@13.0/lib/marked.umd.min.js`,
    lazyload: `/%5Bobject%20Object%5D`
  }
  

</script>

<script type="text/javascript">
  
  function RunItem() {
    this.list = []; // 存放回调函数
    this.start = () => {
      for (var i = 0; i < this.list.length; i++) {
        this.list[i].run();
      }
    };
    this.push = (fn, name, setRequestAnimationFrame = true) => {
      let myfn = fn
      if (setRequestAnimationFrame) {
        myfn = () => {
          utils.requestAnimationFrame(fn)
        }
      }
      var f = new Item(myfn, name);
      this.list.push(f);
    };
    this.remove = (name) => {
      for (let index = 0; index < this.list.length; index++) {
        const e = this.list[index];
        if (e.name == name) {
          this.list.splice(index, 1);
        }
      }
    }
    // 构造一个可以run的对象
    function Item(fn, name) {
      // 函数名称
      this.name = name || fn.name;
      // run方法
      this.run = () => {
        try {
          fn()
        } catch (error) {
          console.log(error);
        }
      };
    }
  }

  const utils = {
    // 懒加载 css https://github.com/filamentgroup/loadCSS
    css: (href, before, media, attributes) => {
      var doc = window.document;
      var ss = doc.createElement("link");
      var ref;
      if (before) {
        ref = before;
      } else {
        var refs = (doc.body || doc.getElementsByTagName("head")[0]).childNodes;
        ref = refs[refs.length - 1];
      }
      var sheets = doc.styleSheets;
      if (attributes) {
        for (var attributeName in attributes) {
          if (attributes.hasOwnProperty(attributeName)) {
            ss.setAttribute(attributeName, attributes[attributeName]);
          }
        }
      }
      ss.rel = "stylesheet";
      ss.href = href;
      ss.media = "only x";
      function ready(cb) {
        if (doc.body) {
          return cb();
        }
        setTimeout(function () {
          ready(cb);
        });
      }
      ready(function () {
        ref.parentNode.insertBefore(ss, before ? ref : ref.nextSibling);
      });
      var onloadcssdefined = function (cb) {
        var resolvedHref = ss.href;
        var i = sheets.length;
        while (i--) {
          if (sheets[i].href === resolvedHref) {
            return cb();
          }
        }
        setTimeout(function () {
          onloadcssdefined(cb);
        });
      };
      function loadCB() {
        if (ss.addEventListener) {
          ss.removeEventListener("load", loadCB);
        }
        ss.media = media || "all";
      }
      if (ss.addEventListener) {
        ss.addEventListener("load", loadCB);
      }
      ss.onloadcssdefined = onloadcssdefined;
      onloadcssdefined(loadCB);
      return ss;
    },

    js: (src, opt) => new Promise((resolve, reject) => {
      var script = document.createElement('script');
      if (src.startsWith('/')) {
        src = ctx.root + src.substring(1);
      }
      script.src = src;
      if (opt) {
        for (let key of Object.keys(opt)) {
          script[key] = opt[key]
        }
      } else {
        // 默认异步，如果需要同步，第二个参数传入 {} 即可
        script.async = true
      }
      script.onerror = reject
      script.onload = script.onreadystatechange = function () {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    }),

    jq: (fn) => {
      if (typeof jQuery === 'undefined') {
        utils.js(deps.jquery).then(fn)
      } else {
        fn()
      }
    },

    onLoading: (el) => {
      if (el) {
        $(el).append('<div class="loading-wrap"><svg xmlns="http://www.w3.org/2000/svg" width="2em" height="2em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 24 24"><g fill="none" stroke="currentColor" stroke-linecap="round" stroke-width="2"><path stroke-dasharray="60" stroke-dashoffset="60" stroke-opacity=".3" d="M12 3C16.9706 3 21 7.02944 21 12C21 16.9706 16.9706 21 12 21C7.02944 21 3 16.9706 3 12C3 7.02944 7.02944 3 12 3Z"><animate fill="freeze" attributeName="stroke-dashoffset" dur="1.3s" values="60;0"/></path><path stroke-dasharray="15" stroke-dashoffset="15" d="M12 3C16.9706 3 21 7.02944 21 12"><animate fill="freeze" attributeName="stroke-dashoffset" dur="0.3s" values="15;0"/><animateTransform attributeName="transform" dur="1.5s" repeatCount="indefinite" type="rotate" values="0 12 12;360 12 12"/></path></g></svg></div>');
      }
    },
    onLoadSuccess: (el) => {
      if (el) {
        $(el).find('.loading-wrap').remove();
      }
    },
    onLoadFailure: (el) => {
      if (el) {
        $(el).find('.loading-wrap svg').remove();
        $(el).find('.loading-wrap').append('<svg xmlns="http://www.w3.org/2000/svg" width="2em" height="2em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 24 24"><g fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2"><path stroke-dasharray="60" stroke-dashoffset="60" d="M12 3L21 20H3L12 3Z"><animate fill="freeze" attributeName="stroke-dashoffset" dur="0.5s" values="60;0"/></path><path stroke-dasharray="6" stroke-dashoffset="6" d="M12 10V14"><animate fill="freeze" attributeName="stroke-dashoffset" begin="0.6s" dur="0.2s" values="6;0"/></path></g><circle cx="12" cy="17" r="1" fill="currentColor" fill-opacity="0"><animate fill="freeze" attributeName="fill-opacity" begin="0.8s" dur="0.4s" values="0;1"/></circle></svg>');
        $(el).find('.loading-wrap').addClass('error');
      }
    },
    request: (el, url, callback, onFailure) => {
      let retryTimes = 3;
      utils.onLoading(el);
      function req() {
        return new Promise((resolve, reject) => {
          let status = 0; // 0 等待 1 完成 2 超时
          let timer = setTimeout(() => {
            if (status === 0) {
              status = 2;
              timer = null;
              reject('请求超时');
              if (retryTimes == 0 && onFailure) {
                onFailure();
              }
            }
          }, 5000);
          fetch(url).then(function (response) {
            if (status !== 2) {
              clearTimeout(timer);
              resolve(response);
              timer = null;
              status = 1;
            }
            if (response.ok) {
              return response;
            }
            throw new Error('Network response was not ok.');
          }).then(function (data) {
            retryTimes = 0;
            utils.onLoadSuccess(el);
            callback(data);
          }).catch(function (error) {
            if (retryTimes > 0) {
              retryTimes -= 1;
              setTimeout(() => {
                req();
              }, 5000);
            } else {
              utils.onLoadFailure(el);
              if (onFailure) {
                onFailure();
              }
            }
          });
        });
      }
      req();
    },
    /********************** requestAnimationFrame ********************************/
    // 1、requestAnimationFrame 会把每一帧中的所有 DOM 操作集中起来，在一次重绘或回流中就完成，并且重绘或回流的时间间隔紧紧跟随浏览器的刷新频率，一般来说，这个频率为每秒60帧。
    // 2、在隐藏或不可见的元素中，requestAnimationFrame 将不会进行重绘或回流，这当然就意味着更少的的 cpu，gpu 和内存使用量。
    requestAnimationFrame: (fn) => {
      if (!window.requestAnimationFrame) {
        window.requestAnimationFrame = window.requestAnimationFrame || window.mozRequestAnimationFrame || window.webkitRequestAnimationFrame;
      }
      window.requestAnimationFrame(fn)
    },
    dark: {},
  };

  // utils.dark.mode 当前模式 dark or light
  // utils.dark.toggle() 暗黑模式触发器
  // utils.dark.push(callBack[,"callBackName"]) 传入触发器回调函数
  utils.dark.method = {
    toggle: new RunItem(),
  };
  utils.dark = Object.assign(utils.dark, {
    push: utils.dark.method.toggle.push,
  });
</script>
<script>
  const sidebar = {
    leftbar: () => {
      if (l_body) {
        l_body.toggleAttribute('leftbar');
        l_body.removeAttribute('rightbar');
      }
    },
    rightbar: () => {
      if (l_body) {
        l_body.toggleAttribute('rightbar');
        l_body.removeAttribute('leftbar');
      }
    },
    dismiss: () => {
      if (l_body) {
        l_body.removeAttribute('leftbar');
        l_body.removeAttribute('rightbar');
      }
    },
    toggleTOC: () => {
      document.querySelector('#data-toc').classList.toggle('collapse');
    }
  }
</script>
<script type="text/javascript">
  (() => {
    const tagSwitchers = document.querySelectorAll('.tag-subtree.parent-tag > a > .tag-switcher-wrapper')
    for (const tagSwitcher of tagSwitchers) {
      tagSwitcher.addEventListener('click', (e) => {
        const parent = e.target.closest('.tag-subtree.parent-tag')
        parent.classList.toggle('expanded')
        e.preventDefault()
      })
    }

    // Get active tag from query string, then activate it.
    const urlParams = new URLSearchParams(window.location.search)
    const activeTag = urlParams.get('tag')
    if (activeTag) {
      let tag = document.querySelector(`.tag-subtree[data-tag="${activeTag}"]`)
      if (tag) {
        tag.querySelector('a').classList.add('active')
        
        while (tag) {
          tag.classList.add('expanded')
          tag = tag.parentElement.closest('.tag-subtree.parent-tag')
        }
      }
    }
  })()
</script>

<script async src="https://gcore.jsdelivr.net/npm/vanilla-lazyload@19.1/dist/lazyload.min.js"></script>
<script>
  // https://www.npmjs.com/package/vanilla-lazyload
  // Set the options globally
  // to make LazyLoad self-initialize
  window.lazyLoadOptions = {
    elements_selector: ".lazy",
    callback_loaded: (el) => {
      el.classList.add('loaded');
      const wrapper = el.closest('.lazy-box');
      const icon = wrapper?.querySelector('.lazy-icon');
      if (icon) icon.remove();
    }
  };
  // Listen to the initialization event
  // and get the instance of LazyLoad
  window.addEventListener(
    "LazyLoad::Initialized",
    function (event) {
      window.lazyLoadInstance = event.detail.instance;
    },
    false
  );
  document.addEventListener('DOMContentLoaded', function () {
    window.lazyLoadInstance?.update();
  });

  window.wrapLazyloadImages = (container) => {
    if (typeof container === 'string') {
      container = document.querySelector(container);
    }
    if (!container) return;
    
    const images = container.querySelectorAll('img');
    images.forEach((img) => {
      if (img.classList.contains('lazy')) return;

      const src = img.getAttribute('src');
      if (!src) return;

      const wrapper = document.createElement('div');
      wrapper.className = 'lazy-box';

      const newImg = img.cloneNode();
      newImg.removeAttribute('src');
      newImg.setAttribute('data-src', src);
      newImg.classList.add('lazy');

      const icon = document.createElement('div');
      icon.className = 'lazy-icon';
      if (def.loading) {
        icon.style.backgroundImage = `url("${def.loading}")`;
      }

      wrapper.appendChild(newImg);
      wrapper.appendChild(icon);

      img.replaceWith(wrapper);
    });

    // 通知 LazyLoad 更新
    if (window.lazyLoadInstance?.update) {
      window.lazyLoadInstance.update();
    }
  }
  
</script>

<!-- required -->
<script src="/js/main.js?v=1.32.4" defer></script>

<script type="text/javascript">
  const applyTheme = (theme) => {
    if (theme === 'auto') {
      document.documentElement.removeAttribute('data-theme')
    } else {
      document.documentElement.setAttribute('data-theme', theme)
    }

    // applyThemeToGiscus(theme)
  }

  // FIXME: 这会导致无法使用 preferred_color_scheme 以外的主题
  const applyThemeToGiscus = (theme) => {
    // theme = theme === 'auto' ? 'preferred_color_scheme' : theme
    const cmt = document.getElementById('giscus')
    if (cmt) {
      // This works before giscus load.
      cmt.setAttribute('data-theme', theme)
    }

    const iframe = document.querySelector('#comments > section.giscus > iframe')
    if (iframe) {
      // This works after giscus loaded.
      const src = iframe.src
      const newSrc = src.replace(/theme=[\w]+/, `theme=${theme}`)
      iframe.src = newSrc
    }
  }

  const switchTheme = () => {
    // light -> dark -> auto -> light -> ...
    const currentTheme = document.documentElement.getAttribute('data-theme')
    let newTheme;
    switch (currentTheme) {
      case 'light':
        newTheme = 'dark'
        break
      case 'dark':
        newTheme = 'auto'
        break
      default:
        newTheme = 'light'
    }
    applyTheme(newTheme)
    window.localStorage.setItem('Stellar.theme', newTheme)
    utils.dark.mode = newTheme === 'auto' ? (window.matchMedia("(prefers-color-scheme: dark)").matches ? "dark" : "light") : newTheme;
    utils.dark.method.toggle.start();

    const messages = {
      light: `切换到浅色模式`,
      dark: `切换到深色模式`,
      auto: `切换到跟随系统配色`,
    }
    hud?.toast?.(messages[newTheme])
  }

  (() => {
    // Apply user's preferred theme, if any.
    const theme = window.localStorage.getItem('Stellar.theme')
    if (theme !== null) {
      applyTheme(theme)
    } else {
      utils.dark.mode = window.matchMedia("(prefers-color-scheme: dark)").matches ? "dark" : "light";
    }
    utils.dark.method.toggle.start();
  })()
</script>


<!-- optional -->



<script defer>
  window.addEventListener('DOMContentLoaded', (event) => {
    ctx.services = Object.assign({}, JSON.parse(`{"mdrender":{"js":"/js/services/mdrender.js"},"siteinfo":{"js":"/js/services/siteinfo.js","api":null},"ghinfo":{"js":"/js/services/ghinfo.js"},"sites":{"js":"/js/services/sites.js"},"friends":{"js":"/js/services/friends.js"},"friends_and_posts":{"js":"/js/services/friends_and_posts.js"},"timeline":{"js":"/js/services/timeline.js"},"fcircle":{"js":"/js/services/fcircle.js"},"weibo":{"js":"/js/services/weibo.js"},"memos":{"js":"/js/services/memos.js"},"voice":{"js":"/js/plugins/voice.js"},"video":{"js":"/js/plugins/video.js"},"download-file":{"js":"/js/plugins/download-file.js"},"twikoo":{"js":"/js/services/twikoo_latest_comment.js"},"waline":{"js":"/js/services/waline_latest_comment.js"},"artalk":{"js":"/js/services/artalk_latest_comment.js"},"giscus":{"js":"/js/services/giscus_latest_comment.js"},"contributors":{"edit_this_page":{"_posts/":null,"wiki/stellar/":"https://github.com/xaoxuu/hexo-theme-stellar-docs/blob/main/"},"js":"/js/services/contributors.js"}}`));
    for (let id of Object.keys(ctx.services)) {
      const js = ctx.services[id].js;
      if (id == 'siteinfo') {
        ctx.cardlinks = document.querySelectorAll('a.link-card[cardlink]');
        if (ctx.cardlinks?.length > 0) {
          utils.js(js, { defer: true }).then(function () {
            setCardLink(ctx.cardlinks);
          });
        }
      } else if (id == 'voice') {
        ctx.voiceAudios = document.querySelectorAll('.voice>audio');
        if (ctx.voiceAudios?.length > 0) {
          utils.js(js, { defer: true }).then(function () {
            createVoiceDom(ctx.voiceAudios);
          });
        }
      } else if (id == 'video') {
        ctx.videos = document.querySelectorAll('.video>video');
        if (ctx.videos?.length > 0) {
          utils.js(js, { defer: true }).then(function () {
            videoEvents(ctx.videos);
          });
        }
      } else if (id == 'download-file') {
        ctx.files = document.querySelectorAll('.file');
        if (ctx.files?.length > 0) {
          utils.js(js, { defer: true }).then(function () {
            downloadFileEvent(ctx.files);
          });
        }
      } else {
        const els = document.getElementsByClassName(`ds-${id}`);
        if (els?.length > 0) {
          utils.jq(() => {
            if (id == 'timeline' || 'memos' || 'marked') {
              utils.js(deps.marked).then(function () {
                utils.js(js, { defer: true });
              });
            } else {
              utils.js(js, { defer: true });
            }
          });
        }
      }
    }

    // chat iphone time
    let phoneTimes = document.querySelectorAll('.chat .status-bar .time');

    if (phoneTimes.length > 0) {
      NowTime();
      var date = new Date();
      var sec = date.getSeconds();
      var firstAdjustInterval = setInterval(firstAdjustTime, 1000 * (60 - sec));
    }

    function firstAdjustTime() {
      NowTime();
      clearInterval(firstAdjustInterval);
      setInterval(NowTime, 1000 * 60);
    }

    function NowTime() {
      for (let i = 0; i < phoneTimes.length; ++i) {
        var timeSpan = phoneTimes[i];
        var date = new Date();
        var hour = date.getHours();
        var min = date.getMinutes();
        timeSpan.innerHTML = check(hour) + ":" + check(min);
      }
    };

    function check(val) {
      if (val < 10) {
        return ("0" + val);
      }
      return (val);
    }

    // chat quote
    const chat_quote_obverser = new IntersectionObserver((entries, observer) => {
      entries.filter((entry) => { return entry.isIntersecting }).sort((a, b) => a.intersectionRect.y !== b.intersectionRect.y ? a.intersectionRect.y - b.intersectionRect.y : a.intersectionRect.x - b.intersectionRect.x).forEach((entry, index) => {
          observer.unobserve(entry.target);
          setTimeout(() => {
            entry.target.classList.add('quote-blink');
            setTimeout(() => {
              entry.target.classList.remove('quote-blink');
            }, 1000);
          }, Math.max(100, 16) * (index + 1));
        });
    });

    var chatQuotes = document.querySelectorAll(".chat .talk .quote");
    chatQuotes.forEach((quote) => {
      quote.addEventListener('click', function () {
        var chatCellDom = document.getElementById("quote-" + quote.getAttribute("quotedCellTag"));
        if (chatCellDom) {
          var chatDiv = chatCellDom.parentElement;
          var mid = chatDiv.clientHeight / 2;
          var offsetTop = chatCellDom.offsetTop;
          if (offsetTop > mid - chatCellDom.clientHeight / 2) {
            chatDiv.scrollTo({
              top: chatCellDom.offsetTop - mid + chatCellDom.clientHeight / 2,
              behavior: "smooth"
            });
          } else {
            chatDiv.scrollTo({
              top: 0,
              behavior: "smooth"
            });
          }
          chat_quote_obverser.observe(chatCellDom);
        }
      });
    });
  });
</script>

<script>
  window.addEventListener('DOMContentLoaded', (event) => {
    ctx.search = {
      path: `/search.json`,
    }
    utils.js('/js/search/local-search.js', { defer: true });
  });
</script><script>
  window.FPConfig = {
    delay: 0,
    ignoreKeywords: [],
    maxRPS: 5,
    hoverDelay: 25
  };
</script>
<script defer src="https://gcore.jsdelivr.net/npm/flying-pages@2/flying-pages.min.js"></script><script>
  ctx.fancybox = {
    selector: `.timenode p>img`,
    css: `https://gcore.jsdelivr.net/npm/@fancyapps/ui@5.0/dist/fancybox/fancybox.css`,
    js: `https://gcore.jsdelivr.net/npm/@fancyapps/ui@5.0/dist/fancybox/fancybox.umd.js`
  };
  var selector = '[data-fancybox]:not(.error), .with-fancybox .atk-content img:not([atk-emoticon])';
  if (ctx.fancybox.selector) {
    selector += `, ${ctx.fancybox.selector}`
  }
  var needFancybox = document.querySelectorAll(selector).length !== 0;
  if (!needFancybox) {
    const memos = document.getElementsByClassName('ds-memos');
    if (memos != undefined && memos.length > 0) {
      needFancybox = true;
    }
    const fancybox = document.getElementsByClassName('with-fancybox');
    if (fancybox != undefined && fancybox.length > 0) {
      needFancybox = true;
    }
  }
  if (needFancybox) {
    utils.css(ctx.fancybox.css);
    utils.js(ctx.fancybox.js, { defer: true }).then(function () {
      Fancybox.bind(selector, {
        hideScrollbar: false,
        Thumbs: {
          autoStart: false,
        },
        caption: (fancybox, slide) => {
          return slide.triggerEl.alt || slide.triggerEl.dataset.caption || null
        }
      });
    })
  }
</script>
<script>
  window.addEventListener('DOMContentLoaded', (event) => {
    const swiper_api = document.getElementById('swiper-api');
    if (swiper_api != undefined) {
      utils.css(`https://unpkg.com/swiper@10.3/swiper-bundle.min.css`);
      utils.js(`https://unpkg.com/swiper@10.3/swiper-bundle.min.js`, { defer: true }).then(function () {
        const effect = swiper_api.getAttribute('effect') || '';
        var swiper = new Swiper('.swiper#swiper-api', {
          slidesPerView: 'auto',
          spaceBetween: 8,
          centeredSlides: true,
          effect: effect,
          rewind: true,
          pagination: {
            el: '.swiper-pagination',
            clickable: true,
          },
          navigation: {
            nextEl: '.swiper-button-next',
            prevEl: '.swiper-button-prev',
          },
        });
      })
    }
  });
</script>
<script>
  document.addEventListener('DOMContentLoaded', function () {
    window.codeElements = document.querySelectorAll('.code');
    if (window.codeElements.length > 0) {
      ctx.copycode = {
        default_text: `Copy`,
        success_text: `Copied`,
        toast: `复制成功`,
      };
      utils.js('/js/plugins/copycode.js');
    }
  });
</script>


<!-- inject -->

</div></body></html>
