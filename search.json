[{"title":"leetcode刷题记录-20250808，day17，二叉树","path":"/2025/08/21/leetcode刷题记录-20250808，day17，二叉树/","content":"LeetCode 刷题记录 - 2025-08-21今天刷题总结如下： 题目 1: Two Sum (LeetCode 1)题目链接: Two Sum难度: Easy 思路使用哈希表存储已访问元素及其下标，遍历数组时查找目标值减去当前值是否存在。 代码示例class Solution: def twoSum(self, nums, target): hashmap = for i, num in enumerate(nums): if target - num in hashmap: return [hashmap[target - num], i] hashmap[num] = i","tags":["刷题","数据结构","算法"],"categories":["LeetCode"]},{"title":"RK3588 平台部署 YOLO11-Seg","path":"/2025/08/21/RK3588-平台-YOLO11-Seg-部署与优化/","content":"本文记录了在 RK3588 开发板上部署 YOLO11-Seg 的流程，涵盖环境准备、模型转换与推理测试。 1. 环境准备此处列出的是我使用的相关环境，由于使用pytorch较多，所以训练框架默认pytorch。PC端需安装pytorch相关环境，环境安装及模型训练不过多说明（因为不是训练调参分享，哈哈）。官方文档环境要求如下，但是经过我实际使用发现，Ubuntu 16.04.7 LT + Python 3.10也可用。 PC端Ubuntu 16.04.7 LTPython 3.10.18Pytorch 2.2.0CUDA 12.1cmake 3.18.4aarch64-linux-gnu-gcc 6.2.1aarch64-linux-gnu-g++ 6.2.1RKNN-Toolkit2 v2.3.2 # 安装 RKNN-Toolkit2# 请根据不同的 python 版本及处理器架构，选择不同的 wheel 安装包文件：# 其中 x.x.x 是 RKNN-Toolkit2 版本号，cpxx 是 python 版本号pip install packages/x86_64/rknn_toolkit2-x.x.x-cpxx-cpxx-manylinux_2_17_x86_64.manylinux2014_x86_64.whl 板端# 查询 NPU 驱动版本dmesg | grep -i rknpu 或cat /sys/kernel/debug/rknpu/version 或cat /sys/kernel/debug/rknpu/driver_version 或cat /proc/debug/rknpu/driver_version# 显示 RKNPU driver: vX.X.X# 查询rknn_server版本strings /usr/bin/rknn_server | grep -i rknn_server version# 显示 rknn_server version: X.X.X# 查询librknnrt.so库版本strings /usr/lib/librknnrt.so | grep -i librknnrt version# 显示 librknnrt version: X.X.X 2. 模型转换模型转换分为两步，第一步由训练好的.pt转为.onnx，第二步从.onnx转为RKNPU可用的.rknn格式模型。模型训练框架使用的是YOLO11-Seg官方的版本(Ultralytics)。转换onnx同样有两种方式，第一种是利用Ultralytics提供直接导出.rknn格式的接口，我暂时未使用，大家可以试一下。第二种方式用rockchip提供的YOLO11代码导出(https://github.com/airockchip/ultralytics_yolo11). # 调整 ./ultralytics/cfg/default.yaml 中 model 文件路径，默认为 yolo11n.pt，若自己训练模型，请调接至对应的路径。python ./ultralytics/engine/exporter.py# 执行完毕后，会生成 ONNX 模型. 假如原始模型为 yolo11n.pt，则生成 yolo11n.onnx 模型。 rockchip修改了输出信息。官方版本导出onnx后只有一个输出[1, 84, 8400], 下图是通过rockchip提供代码导出。 转换onnx完成后，可以测试推理效果，一般情况下与pt结果一致。测试无误后利用rknn的api进行rknn模型转换，这里仅贴部分代码，完整代码会在仿真测试后给出。 # 创建 RKNN 对象rknn = RKNN(verbose=False)# 参数设置，这里做了归一化，在后续C代码中就不需要了，目标平台根据自己需求选择。rknn.config(mean_values=[[0, 0, 0]], std_values=[[255, 255, 255]], target_platform=platform)# 加载 onnx 模型ret = rknn.load_onnx(model=model_path)# 构建，这里可选是否对模型做量化，RK3588上只支持i8以及fp16格式。ret = rknn.build(do_quantization=do_quant, dataset=DATASET_PATH)# 开导ret = rknn.export_rknn(output_path) 3. 仿真测试仿真正确是上版正确的前提！！话不多说，直接上代码。 # 在仿真时这个的target要设置为None。ret = rknn.init_runtime(target=None, device_id=None, perf_debug=False)# 这里的 img 要经过前处理，比如补尺寸（letterbox），注意通过cv2.imread读进来的图片默认是BGR格式，如果你的模型接收的格式是RGB需要做转换outputs = rknn.inference(inputs=[img]) 完整代码！！ 点击展开代码 import osimport sysimport numpy as npfrom rknn.api import RKNNrealpath = os.path.abspath(__file__)_sep = os.path.seprealpath = realpath.split(_sep)sys.path.append(os.path.join(realpath[0]+_sep, *realpath[1:realpath.index(rknn_model_zoo-main)+1]))from py_utils.coco_utils import COCO_test_helperimport cv2from yolo11_seg import merge_seg, post_processDATASET_PATH = xxxDEFAULT_RKNN_PATH = xxxDEFAULT_QUANT = Trueimg_path = xxxdef parse_arg(): if len(sys.argv) 3: print(Usage: python3 onnx_model_path [platform] [dtype(optional)] [output_rknn_path(optional)].format(sys.argv[0])); print( platform choose from [rk3562, rk3566, rk3568, rk3576, rk3588, rv1126b, rv1109, rv1126, rk1808]) print( dtype choose from [i8, fp] for [rk3562, rk3566, rk3568, rk3576, rk3588, rv1126b]) print( dtype choose from [u8, fp] for [rv1109, rv1126, rk1808]) exit(1) model_path = sys.argv[1] platform = sys.argv[2] do_quant = DEFAULT_QUANT if len(sys.argv) 3: model_type = sys.argv[3] if model_type not in [i8, u8, fp]: print(ERROR: Invalid model type: .format(model_type)) exit(1) elif model_type in [i8, u8]: do_quant = True else: do_quant = False if len(sys.argv) 4: output_path = sys.argv[4] else: output_path = DEFAULT_RKNN_PATH return model_path, platform, do_quant, output_pathif __name__ == __main__: model_path, platform, do_quant, output_path = parse_arg() # 创建 RKNN 对象 rknn = RKNN(verbose=False) # 参数设置，这里做了归一化，在后续C代码中就不需要了，目标平台根据自己需求选择。 print(-- Config model) rknn.config(mean_values=[[0, 0, 0]], std_values=[[255, 255, 255]], target_platform=platform) print(done) # 加载 onnx 模型 print(-- Loading model) ret = rknn.load_onnx(model=model_path) if ret != 0: print(Load model failed!) exit(ret) print(done) # 构建，这里可选是否对模型做量化，RK3588上只支持i8以及fp16格式。 print(-- Building model) ret = rknn.build(do_quantization=do_quant, dataset=DATASET_PATH) if ret != 0: print(Build model failed!) exit(ret) print(done) # 在仿真时这个的target要设置为None。 print(-- Init runtime environment) ret = rknn.init_runtime(target=None, device_id=None, perf_debug=False) if ret != 0: print(Init runtime environment failed!) exit(ret) print(done) # 这里可选仿真精度分析，可以查看每一层结果差异 # # print(-- Accuracy analysis) # Ret = rknn.accuracy_analysis(inputs=[img_path], # target=None) # if ret != 0: # print(Accuracy analysis failed!) # exit(ret) # print(done) # 开导 print(-- Export rknn model) ret = rknn.export_rknn(output_path) if ret != 0: print(Export rknn model failed!) exit(ret) print(done) # 官方提供了接口直接生成C代码，简化了开发流程，可以在此基础上进行二次开发，目前我用这部分代码只测试精度。 # print(-- codegen) # ret = rknn.codegen(output_path=./rknn_app_demo, # inputs=[img_path], overwrite=True) # if ret != 0: # print(Export rknn model failed!) # exit(ret) # print(done) IMG_SIZE = (640, 640) # (width, height) co_helper = COCO_test_helper(enable_letter_box=True) img_src = cv2.imread(img_path) img = co_helper.letter_box(im= img_src.copy(), new_shape=(IMG_SIZE[1], IMG_SIZE[0]), pad_color=(114, 114, 114)) img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) img = np.expand_dims(img, 0); # 这里的 img 要经过前处理，比如补尺寸（letterbox），注意通过cv2.imread读进来的图片默认是BGR格式，如果你的模型接收的格式是RGB需要做转换 print(-- Running model) outputs = rknn.inference(inputs=[img]) print(done) boxes, classes, scores, seg_img = post_process(outputs) if boxes is not None: real_boxs = co_helper.get_real_box(boxes) real_segs = co_helper.get_real_seg(seg_img) img_p = merge_seg(img_src, real_segs, classes) img_output_path = ./xxx if not os.path.exists(img_output_path): os.mkdir(img_output_path) result_path = os.path.join(img_output_path, xxx.png) cv2.imwrite(result_path, img_p) print(saved to .format(result_path)) # Release rknn.release() 4. 编译及上版测试编写C代码，只是想测试的话可以直接使用官方提供的yolov8-seg的demo，因为前后处理是一样的操作，后续我会把我的代码链接放进来（其实是还没整理好，太乱了）。PC端测试、仿真测试以及上版测试结果如下。后续会更新优化部分。","tags":["RK3588","YOLO11","目标检测","实例分割"],"categories":["AI部署"]},{"title":"关于","path":"/about/index.html","content":"友链关于昵称简介 关于本站 本站没有任何推广和打赏链接，如果您觉得哪个作品不错，欢迎去对应的仓库点个赞，或者在对应的文章下面留言互动一下。 开源项目无任何盈利目的，只在工作闲暇时间进行维护，有相关需求请前往对应项目提 Issue 进行反馈，通过私人邮件询问开源项目问题可能得不到答复。"},{"title":"收藏","path":"/bookmark/index.html","content":"…"},{"title":"探索","path":"/explore/index.html","content":"…"},{"title":"友链","path":"/friends/index.html","content":"友链关于小伙伴们如果宇宙中真有什么终极的逻辑，那就是我们终有一天会在舰桥上重逢，直到生命终结。 [2023-12] 友链失联了怎么办? 添加友链后如果网站长期无法访问，可能会被取消友链！如果您的网站恢复了，可以在申请友链时创建的那条 issue 中评论告知。 朋友们近期的文章 如何交换友链？ 您的网站应满足以下全部条件： 安全合规：合法的、非营利性、无木马植入的 HTTPS 站点。 非空壳网站：网站内发布至少 五篇 原创文章，内容题材不限。 我们需要有一定的有效互动： 先友后链：与博主有至少 半年 的有效互动，例如 issue 或者评论留言。 [2023-12] 友链申请条件变更说明 降低了对商业广告的要求，可以有但是不能太多。提高了「有效互动」的定义：5次更改为半年。 我已满足全部条件，快告诉我如何交换友链！ 如果您没有满足上述条件，即时提交了申请也不会通过哦～ 第一步：新建 Issue新建 GitHub Issue 按照模板格式填写并提交。为了提高图片加载速度，建议优化头像：打开 压缩图 上传自己的头像，将图片尺寸调整到 144px 后下载。将压缩后的图片上传到 去不图床 或者其它稳定的图床并使用此图片链接作为头像。第二步：添加友链并等待管理员审核请添加本站到您的友链中：title: xxxurl: https://xxx.comavatar: screenshot: 待管理员审核通过，添加了 active 标签后，回来刷新即可生效。如果您需要更新自己的友链，请直接修改 issue 内容，大约 3 分钟内生效，无需等待博客重新部署。"},{"title":"Page","path":"/page/index.html","content":"This is a page test."},{"title":"朋友文章","path":"/friends/rss/index.html","content":""}]